{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from flaml import AutoML\n",
    "except ModuleNotFoundError:\n",
    "    !pip install flaml\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix, f1_score, precision_score, \\\n",
    "                            recall_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Samples: 569\n",
      "Validation Dataset Samples: 143\n",
      "Testing Dataset Samples: 179\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    data = pd.read_csv(\"data/processed_data.csv\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    # Download processed data:\n",
    "    address = 'https://raw.githubusercontent.com/MichaelAllen1966/' + \\\n",
    "                '1804_python_healthcare/master/titanic/data/processed_data.csv'\n",
    "\n",
    "    data = pd.read_csv(address)\n",
    "\n",
    "    # Create a data subfolder if one does not already exist\n",
    "    import os\n",
    "    data_directory ='./data/'\n",
    "    if not os.path.exists(data_directory):\n",
    "        os.makedirs(data_directory)\n",
    "\n",
    "    # Save data\n",
    "    data.to_csv(data_directory + 'processed_data.csv', index=False)\n",
    "\n",
    "data = data.astype(float)\n",
    "\n",
    "# Drop Passengerid (axis=1 indicates we are removing a column rather than a row)\n",
    "# We drop passenger ID as it is not original data\n",
    "\n",
    "data.drop('PassengerId', inplace=True, axis=1)\n",
    "\n",
    "X = data.drop('Survived',axis=1) # X = all 'data' except the 'survived' column\n",
    "y = data['Survived'] # y = 'survived' column from 'data'\n",
    "\n",
    "feature_names = X.columns.tolist()\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training Dataset Samples: {len(X_train)}\")\n",
    "print(f\"Validation Dataset Samples: {len(X_validate)}\")\n",
    "print(f\"Testing Dataset Samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple initial auto ML training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 07-22 14:09:24] {1680} INFO - task = classification\n",
      "[flaml.automl.logger: 07-22 14:09:24] {1691} INFO - Evaluation method: cv\n",
      "[flaml.automl.logger: 07-22 14:09:24] {1789} INFO - Minimizing error metric: 1-roc_auc\n",
      "[flaml.automl.logger: 07-22 14:09:24] {1901} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'lrl1']\n",
      "[flaml.automl.logger: 07-22 14:09:24] {2219} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:09:24] {2345} INFO - Estimated sufficient time budget=450s. Estimated necessary time budget=11s.\n",
      "[flaml.automl.logger: 07-22 14:09:24] {2392} INFO -  at 0.1s,\testimator lgbm's best error=0.1860,\tbest estimator lgbm's best error=0.1860\n",
      "[flaml.automl.logger: 07-22 14:09:24] {2219} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:09:24] {2392} INFO -  at 0.1s,\testimator lgbm's best error=0.1614,\tbest estimator lgbm's best error=0.1614\n",
      "[flaml.automl.logger: 07-22 14:09:24] {2219} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:09:25] {2392} INFO -  at 0.2s,\testimator lgbm's best error=0.1516,\tbest estimator lgbm's best error=0.1516\n",
      "[flaml.automl.logger: 07-22 14:09:25] {2219} INFO - iteration 3, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:09:25] {2392} INFO -  at 0.3s,\testimator xgboost's best error=0.1834,\tbest estimator lgbm's best error=0.1516\n",
      "[flaml.automl.logger: 07-22 14:09:25] {2219} INFO - iteration 4, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:09:25] {2392} INFO -  at 0.3s,\testimator lgbm's best error=0.1468,\tbest estimator lgbm's best error=0.1468\n",
      "[flaml.automl.logger: 07-22 14:09:25] {2219} INFO - iteration 5, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:09:25] {2392} INFO -  at 0.4s,\testimator lgbm's best error=0.1460,\tbest estimator lgbm's best error=0.1460\n",
      "[flaml.automl.logger: 07-22 14:09:25] {2219} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:09:25] {2392} INFO -  at 0.4s,\testimator lgbm's best error=0.1460,\tbest estimator lgbm's best error=0.1460\n",
      "[flaml.automl.logger: 07-22 14:09:25] {2219} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:09:25] {2392} INFO -  at 0.5s,\testimator lgbm's best error=0.1460,\tbest estimator lgbm's best error=0.1460\n",
      "[flaml.automl.logger: 07-22 14:09:25] {2219} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:09:25] {2392} INFO -  at 0.5s,\testimator lgbm's best error=0.1416,\tbest estimator lgbm's best error=0.1416\n",
      "[flaml.automl.logger: 07-22 14:09:25] {2219} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:09:25] {2392} INFO -  at 0.5s,\testimator lgbm's best error=0.1416,\tbest estimator lgbm's best error=0.1416\n",
      "[flaml.automl.logger: 07-22 14:09:25] {2219} INFO - iteration 10, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:09:25] {2392} INFO -  at 0.6s,\testimator xgboost's best error=0.1834,\tbest estimator lgbm's best error=0.1416\n",
      "[flaml.automl.logger: 07-22 14:09:25] {2219} INFO - iteration 11, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:09:25] {2392} INFO -  at 0.7s,\testimator xgboost's best error=0.1482,\tbest estimator lgbm's best error=0.1416\n",
      "[flaml.automl.logger: 07-22 14:09:25] {2219} INFO - iteration 12, current learner extra_tree\n",
      "[flaml.automl.logger: 07-22 14:09:25] {2392} INFO -  at 0.9s,\testimator extra_tree's best error=0.1707,\tbest estimator lgbm's best error=0.1416\n",
      "[flaml.automl.logger: 07-22 14:09:25] {2219} INFO - iteration 13, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:09:25] {2392} INFO -  at 1.2s,\testimator rf's best error=0.1907,\tbest estimator lgbm's best error=0.1416\n",
      "[flaml.automl.logger: 07-22 14:09:25] {2219} INFO - iteration 14, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:09:26] {2392} INFO -  at 1.5s,\testimator rf's best error=0.1907,\tbest estimator lgbm's best error=0.1416\n",
      "[flaml.automl.logger: 07-22 14:09:26] {2219} INFO - iteration 15, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:09:26] {2392} INFO -  at 1.6s,\testimator xgboost's best error=0.1465,\tbest estimator lgbm's best error=0.1416\n",
      "[flaml.automl.logger: 07-22 14:09:26] {2219} INFO - iteration 16, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:09:26] {2392} INFO -  at 1.6s,\testimator lgbm's best error=0.1416,\tbest estimator lgbm's best error=0.1416\n",
      "[flaml.automl.logger: 07-22 14:09:26] {2219} INFO - iteration 17, current learner extra_tree\n",
      "[flaml.automl.logger: 07-22 14:09:26] {2392} INFO -  at 2.0s,\testimator extra_tree's best error=0.1707,\tbest estimator lgbm's best error=0.1416\n",
      "[flaml.automl.logger: 07-22 14:09:26] {2219} INFO - iteration 18, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:09:26] {2392} INFO -  at 2.0s,\testimator lgbm's best error=0.1416,\tbest estimator lgbm's best error=0.1416\n",
      "[flaml.automl.logger: 07-22 14:09:26] {2219} INFO - iteration 19, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:09:26] {2392} INFO -  at 2.1s,\testimator xgboost's best error=0.1426,\tbest estimator lgbm's best error=0.1416\n",
      "[flaml.automl.logger: 07-22 14:09:26] {2219} INFO - iteration 20, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:09:27] {2392} INFO -  at 2.2s,\testimator xgboost's best error=0.1426,\tbest estimator lgbm's best error=0.1416\n",
      "[flaml.automl.logger: 07-22 14:09:27] {2219} INFO - iteration 21, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:09:27] {2392} INFO -  at 2.3s,\testimator xgboost's best error=0.1409,\tbest estimator xgboost's best error=0.1409\n",
      "[flaml.automl.logger: 07-22 14:09:27] {2219} INFO - iteration 22, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:09:27] {2392} INFO -  at 2.3s,\testimator lgbm's best error=0.1383,\tbest estimator lgbm's best error=0.1383\n",
      "[flaml.automl.logger: 07-22 14:09:27] {2219} INFO - iteration 23, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:09:27] {2392} INFO -  at 2.4s,\testimator lgbm's best error=0.1383,\tbest estimator lgbm's best error=0.1383\n",
      "[flaml.automl.logger: 07-22 14:09:27] {2219} INFO - iteration 24, current learner extra_tree\n",
      "[flaml.automl.logger: 07-22 14:09:27] {2392} INFO -  at 2.6s,\testimator extra_tree's best error=0.1707,\tbest estimator lgbm's best error=0.1383\n",
      "[flaml.automl.logger: 07-22 14:09:27] {2219} INFO - iteration 25, current learner extra_tree\n",
      "[flaml.automl.logger: 07-22 14:09:27] {2392} INFO -  at 2.9s,\testimator extra_tree's best error=0.1679,\tbest estimator lgbm's best error=0.1383\n",
      "[flaml.automl.logger: 07-22 14:09:27] {2219} INFO - iteration 26, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:09:27] {2392} INFO -  at 2.9s,\testimator lgbm's best error=0.1383,\tbest estimator lgbm's best error=0.1383\n",
      "[flaml.automl.logger: 07-22 14:09:27] {2219} INFO - iteration 27, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:09:28] {2392} INFO -  at 3.2s,\testimator rf's best error=0.1598,\tbest estimator lgbm's best error=0.1383\n",
      "[flaml.automl.logger: 07-22 14:09:28] {2219} INFO - iteration 28, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:09:28] {2392} INFO -  at 3.3s,\testimator xgboost's best error=0.1409,\tbest estimator lgbm's best error=0.1383\n",
      "[flaml.automl.logger: 07-22 14:09:28] {2219} INFO - iteration 29, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:09:28] {2392} INFO -  at 3.4s,\testimator xgboost's best error=0.1409,\tbest estimator lgbm's best error=0.1383\n",
      "[flaml.automl.logger: 07-22 14:09:28] {2219} INFO - iteration 30, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:09:28] {2392} INFO -  at 3.4s,\testimator lgbm's best error=0.1383,\tbest estimator lgbm's best error=0.1383\n",
      "[flaml.automl.logger: 07-22 14:09:28] {2219} INFO - iteration 31, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:09:28] {2392} INFO -  at 3.5s,\testimator lgbm's best error=0.1383,\tbest estimator lgbm's best error=0.1383\n",
      "[flaml.automl.logger: 07-22 14:09:28] {2219} INFO - iteration 32, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:09:28] {2392} INFO -  at 3.6s,\testimator lgbm's best error=0.1383,\tbest estimator lgbm's best error=0.1383\n",
      "[flaml.automl.logger: 07-22 14:09:28] {2219} INFO - iteration 33, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:09:28] {2392} INFO -  at 3.6s,\testimator xgboost's best error=0.1371,\tbest estimator xgboost's best error=0.1371\n",
      "[flaml.automl.logger: 07-22 14:09:28] {2219} INFO - iteration 34, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:09:28] {2392} INFO -  at 3.7s,\testimator lgbm's best error=0.1383,\tbest estimator xgboost's best error=0.1371\n",
      "[flaml.automl.logger: 07-22 14:09:28] {2219} INFO - iteration 35, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:09:28] {2392} INFO -  at 3.9s,\testimator rf's best error=0.1540,\tbest estimator xgboost's best error=0.1371\n",
      "[flaml.automl.logger: 07-22 14:09:28] {2219} INFO - iteration 36, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:09:28] {2392} INFO -  at 4.1s,\testimator xgboost's best error=0.1371,\tbest estimator xgboost's best error=0.1371\n",
      "[flaml.automl.logger: 07-22 14:09:28] {2219} INFO - iteration 37, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:09:29] {2392} INFO -  at 4.2s,\testimator xgboost's best error=0.1371,\tbest estimator xgboost's best error=0.1371\n",
      "[flaml.automl.logger: 07-22 14:09:29] {2219} INFO - iteration 38, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:09:29] {2392} INFO -  at 4.4s,\testimator xgboost's best error=0.1371,\tbest estimator xgboost's best error=0.1371\n",
      "[flaml.automl.logger: 07-22 14:09:29] {2219} INFO - iteration 39, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:09:29] {2392} INFO -  at 4.5s,\testimator lgbm's best error=0.1383,\tbest estimator xgboost's best error=0.1371\n",
      "[flaml.automl.logger: 07-22 14:09:29] {2219} INFO - iteration 40, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:09:29] {2392} INFO -  at 4.6s,\testimator xgboost's best error=0.1371,\tbest estimator xgboost's best error=0.1371\n",
      "[flaml.automl.logger: 07-22 14:09:29] {2219} INFO - iteration 41, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:09:29] {2392} INFO -  at 4.7s,\testimator xgboost's best error=0.1371,\tbest estimator xgboost's best error=0.1371\n",
      "[flaml.automl.logger: 07-22 14:09:29] {2219} INFO - iteration 42, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:09:29] {2392} INFO -  at 4.8s,\testimator lgbm's best error=0.1383,\tbest estimator xgboost's best error=0.1371\n",
      "[flaml.automl.logger: 07-22 14:09:29] {2219} INFO - iteration 43, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:09:29] {2392} INFO -  at 4.9s,\testimator xgboost's best error=0.1371,\tbest estimator xgboost's best error=0.1371\n",
      "[flaml.automl.logger: 07-22 14:09:29] {2219} INFO - iteration 44, current learner extra_tree\n",
      "[flaml.automl.logger: 07-22 14:09:29] {2392} INFO -  at 5.1s,\testimator extra_tree's best error=0.1679,\tbest estimator xgboost's best error=0.1371\n",
      "[flaml.automl.logger: 07-22 14:09:29] {2219} INFO - iteration 45, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:09:30] {2392} INFO -  at 5.2s,\testimator xgboost's best error=0.1371,\tbest estimator xgboost's best error=0.1371\n",
      "[flaml.automl.logger: 07-22 14:09:30] {2219} INFO - iteration 46, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:09:30] {2392} INFO -  at 5.3s,\testimator lgbm's best error=0.1383,\tbest estimator xgboost's best error=0.1371\n",
      "[flaml.automl.logger: 07-22 14:09:30] {2219} INFO - iteration 47, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:09:30] {2392} INFO -  at 5.4s,\testimator xgboost's best error=0.1342,\tbest estimator xgboost's best error=0.1342\n",
      "[flaml.automl.logger: 07-22 14:09:30] {2219} INFO - iteration 48, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:09:31] {2392} INFO -  at 6.2s,\testimator catboost's best error=0.1326,\tbest estimator catboost's best error=0.1326\n",
      "[flaml.automl.logger: 07-22 14:09:31] {2219} INFO - iteration 49, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:09:31] {2392} INFO -  at 6.3s,\testimator lgbm's best error=0.1383,\tbest estimator catboost's best error=0.1326\n",
      "[flaml.automl.logger: 07-22 14:09:31] {2219} INFO - iteration 50, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:09:32] {2392} INFO -  at 7.5s,\testimator catboost's best error=0.1326,\tbest estimator catboost's best error=0.1326\n",
      "[flaml.automl.logger: 07-22 14:09:32] {2219} INFO - iteration 51, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:09:32] {2392} INFO -  at 7.6s,\testimator xgboost's best error=0.1342,\tbest estimator catboost's best error=0.1326\n",
      "[flaml.automl.logger: 07-22 14:09:32] {2219} INFO - iteration 52, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:09:32] {2392} INFO -  at 8.1s,\testimator rf's best error=0.1540,\tbest estimator catboost's best error=0.1326\n",
      "[flaml.automl.logger: 07-22 14:09:32] {2219} INFO - iteration 53, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:09:34] {2392} INFO -  at 9.9s,\testimator catboost's best error=0.1326,\tbest estimator catboost's best error=0.1326\n",
      "[flaml.automl.logger: 07-22 14:09:34] {2219} INFO - iteration 54, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:09:34] {2392} INFO -  at 10.1s,\testimator lgbm's best error=0.1383,\tbest estimator catboost's best error=0.1326\n",
      "[flaml.automl.logger: 07-22 14:09:34] {2219} INFO - iteration 55, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:09:35] {2392} INFO -  at 10.2s,\testimator lgbm's best error=0.1383,\tbest estimator catboost's best error=0.1326\n",
      "[flaml.automl.logger: 07-22 14:09:35] {2219} INFO - iteration 56, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:09:35] {2392} INFO -  at 10.6s,\testimator xgboost's best error=0.1342,\tbest estimator catboost's best error=0.1326\n",
      "[flaml.automl.logger: 07-22 14:09:35] {2219} INFO - iteration 57, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:09:36] {2392} INFO -  at 11.8s,\testimator rf's best error=0.1540,\tbest estimator catboost's best error=0.1326\n",
      "[flaml.automl.logger: 07-22 14:09:36] {2219} INFO - iteration 58, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:09:39] {2392} INFO -  at 14.2s,\testimator catboost's best error=0.1326,\tbest estimator catboost's best error=0.1326\n",
      "[flaml.automl.logger: 07-22 14:09:39] {2219} INFO - iteration 59, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:09:39] {2392} INFO -  at 14.5s,\testimator xgboost's best error=0.1342,\tbest estimator catboost's best error=0.1326\n",
      "[flaml.automl.logger: 07-22 14:09:39] {2219} INFO - iteration 60, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:09:39] {2392} INFO -  at 14.7s,\testimator lgbm's best error=0.1383,\tbest estimator catboost's best error=0.1326\n",
      "[flaml.automl.logger: 07-22 14:09:39] {2219} INFO - iteration 61, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:09:39] {2392} INFO -  at 14.9s,\testimator xgboost's best error=0.1342,\tbest estimator catboost's best error=0.1326\n",
      "[flaml.automl.logger: 07-22 14:09:39] {2219} INFO - iteration 62, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:09:39] {2392} INFO -  at 15.1s,\testimator lgbm's best error=0.1383,\tbest estimator catboost's best error=0.1326\n",
      "[flaml.automl.logger: 07-22 14:09:39] {2219} INFO - iteration 63, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:09:40] {2392} INFO -  at 15.4s,\testimator xgboost's best error=0.1335,\tbest estimator catboost's best error=0.1326\n",
      "[flaml.automl.logger: 07-22 14:09:40] {2219} INFO - iteration 64, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:09:40] {2392} INFO -  at 15.7s,\testimator xgb_limitdepth's best error=0.1406,\tbest estimator catboost's best error=0.1326\n",
      "[flaml.automl.logger: 07-22 14:09:40] {2219} INFO - iteration 65, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:09:40] {2392} INFO -  at 15.9s,\testimator xgb_limitdepth's best error=0.1406,\tbest estimator catboost's best error=0.1326\n",
      "[flaml.automl.logger: 07-22 14:09:40] {2219} INFO - iteration 66, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:09:41] {2392} INFO -  at 16.3s,\testimator xgboost's best error=0.1335,\tbest estimator catboost's best error=0.1326\n",
      "[flaml.automl.logger: 07-22 14:09:41] {2219} INFO - iteration 67, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:09:41] {2392} INFO -  at 16.6s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator xgb_limitdepth's best error=0.1324\n",
      "[flaml.automl.logger: 07-22 14:09:41] {2219} INFO - iteration 68, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:09:41] {2392} INFO -  at 16.8s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator xgb_limitdepth's best error=0.1324\n",
      "[flaml.automl.logger: 07-22 14:09:41] {2219} INFO - iteration 69, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:09:41] {2392} INFO -  at 17.1s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator xgb_limitdepth's best error=0.1324\n",
      "[flaml.automl.logger: 07-22 14:09:41] {2219} INFO - iteration 70, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:09:42] {2392} INFO -  at 17.2s,\testimator lgbm's best error=0.1383,\tbest estimator xgb_limitdepth's best error=0.1324\n",
      "[flaml.automl.logger: 07-22 14:09:42] {2219} INFO - iteration 71, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:09:42] {2392} INFO -  at 17.4s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator xgb_limitdepth's best error=0.1324\n",
      "[flaml.automl.logger: 07-22 14:09:42] {2219} INFO - iteration 72, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:09:42] {2392} INFO -  at 17.8s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator xgb_limitdepth's best error=0.1324\n",
      "[flaml.automl.logger: 07-22 14:09:42] {2219} INFO - iteration 73, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:09:42] {2392} INFO -  at 18.0s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator xgb_limitdepth's best error=0.1324\n",
      "[flaml.automl.logger: 07-22 14:09:42] {2219} INFO - iteration 74, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:09:43] {2392} INFO -  at 18.3s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator xgb_limitdepth's best error=0.1324\n",
      "[flaml.automl.logger: 07-22 14:09:43] {2219} INFO - iteration 75, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:09:43] {2392} INFO -  at 18.4s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator xgb_limitdepth's best error=0.1324\n",
      "[flaml.automl.logger: 07-22 14:09:43] {2219} INFO - iteration 76, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:09:43] {2392} INFO -  at 18.8s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator xgb_limitdepth's best error=0.1324\n",
      "[flaml.automl.logger: 07-22 14:09:43] {2219} INFO - iteration 77, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:09:43] {2392} INFO -  at 18.9s,\testimator lgbm's best error=0.1383,\tbest estimator xgb_limitdepth's best error=0.1324\n",
      "[flaml.automl.logger: 07-22 14:09:43] {2219} INFO - iteration 78, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:09:43] {2392} INFO -  at 19.0s,\testimator lgbm's best error=0.1383,\tbest estimator xgb_limitdepth's best error=0.1324\n",
      "[flaml.automl.logger: 07-22 14:09:43] {2219} INFO - iteration 79, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:09:44] {2392} INFO -  at 19.2s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator xgb_limitdepth's best error=0.1324\n",
      "[flaml.automl.logger: 07-22 14:09:44] {2219} INFO - iteration 80, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:09:44] {2392} INFO -  at 19.6s,\testimator xgboost's best error=0.1335,\tbest estimator xgb_limitdepth's best error=0.1324\n",
      "[flaml.automl.logger: 07-22 14:09:44] {2219} INFO - iteration 81, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:09:44] {2392} INFO -  at 19.9s,\testimator rf's best error=0.1535,\tbest estimator xgb_limitdepth's best error=0.1324\n",
      "[flaml.automl.logger: 07-22 14:09:44] {2219} INFO - iteration 82, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:09:45] {2392} INFO -  at 20.3s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator xgb_limitdepth's best error=0.1324\n",
      "[flaml.automl.logger: 07-22 14:09:45] {2219} INFO - iteration 83, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:09:46] {2392} INFO -  at 22.0s,\testimator catboost's best error=0.1326,\tbest estimator xgb_limitdepth's best error=0.1324\n",
      "[flaml.automl.logger: 07-22 14:09:46] {2219} INFO - iteration 84, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:09:47] {2392} INFO -  at 22.2s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator xgb_limitdepth's best error=0.1324\n",
      "[flaml.automl.logger: 07-22 14:09:47] {2219} INFO - iteration 85, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:09:47] {2392} INFO -  at 22.7s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator xgb_limitdepth's best error=0.1324\n",
      "[flaml.automl.logger: 07-22 14:09:47] {2219} INFO - iteration 86, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:09:47] {2392} INFO -  at 22.9s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator xgb_limitdepth's best error=0.1324\n",
      "[flaml.automl.logger: 07-22 14:09:47] {2219} INFO - iteration 87, current learner extra_tree\n",
      "[flaml.automl.logger: 07-22 14:09:48] {2392} INFO -  at 23.7s,\testimator extra_tree's best error=0.1679,\tbest estimator xgb_limitdepth's best error=0.1324\n",
      "[flaml.automl.logger: 07-22 14:09:48] {2219} INFO - iteration 88, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:09:48] {2392} INFO -  at 24.0s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator xgb_limitdepth's best error=0.1324\n",
      "[flaml.automl.logger: 07-22 14:09:48] {2219} INFO - iteration 89, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:09:50] {2392} INFO -  at 25.8s,\testimator catboost's best error=0.1326,\tbest estimator xgb_limitdepth's best error=0.1324\n",
      "[flaml.automl.logger: 07-22 14:09:50] {2219} INFO - iteration 90, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:09:52] {2392} INFO -  at 27.5s,\testimator catboost's best error=0.1326,\tbest estimator xgb_limitdepth's best error=0.1324\n",
      "[flaml.automl.logger: 07-22 14:09:52] {2219} INFO - iteration 91, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:09:52] {2392} INFO -  at 27.9s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator xgb_limitdepth's best error=0.1324\n",
      "[flaml.automl.logger: 07-22 14:09:52] {2219} INFO - iteration 92, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:09:52] {2392} INFO -  at 28.1s,\testimator xgboost's best error=0.1335,\tbest estimator xgb_limitdepth's best error=0.1324\n",
      "[flaml.automl.logger: 07-22 14:09:52] {2219} INFO - iteration 93, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:09:53] {2392} INFO -  at 28.3s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator xgb_limitdepth's best error=0.1324\n",
      "[flaml.automl.logger: 07-22 14:09:53] {2219} INFO - iteration 94, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:09:53] {2392} INFO -  at 28.6s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator xgb_limitdepth's best error=0.1324\n",
      "[flaml.automl.logger: 07-22 14:09:53] {2219} INFO - iteration 95, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:09:54] {2392} INFO -  at 29.4s,\testimator xgboost's best error=0.1335,\tbest estimator xgb_limitdepth's best error=0.1324\n",
      "[flaml.automl.logger: 07-22 14:09:54] {2219} INFO - iteration 96, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:09:54] {2392} INFO -  at 29.5s,\testimator lgbm's best error=0.1335,\tbest estimator xgb_limitdepth's best error=0.1324\n",
      "[flaml.automl.logger: 07-22 14:09:54] {2219} INFO - iteration 97, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:09:54] {2392} INFO -  at 29.8s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator xgb_limitdepth's best error=0.1324\n",
      "[flaml.automl.logger: 07-22 14:09:54] {2219} INFO - iteration 98, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:09:54] {2392} INFO -  at 29.9s,\testimator lgbm's best error=0.1335,\tbest estimator xgb_limitdepth's best error=0.1324\n",
      "[flaml.automl.logger: 07-22 14:09:54] {2219} INFO - iteration 99, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:09:56] {2392} INFO -  at 31.6s,\testimator catboost's best error=0.1326,\tbest estimator xgb_limitdepth's best error=0.1324\n",
      "[flaml.automl.logger: 07-22 14:09:56] {2219} INFO - iteration 100, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:09:56] {2392} INFO -  at 31.9s,\testimator lgbm's best error=0.1335,\tbest estimator xgb_limitdepth's best error=0.1324\n",
      "[flaml.automl.logger: 07-22 14:09:56] {2219} INFO - iteration 101, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:09:56] {2392} INFO -  at 32.0s,\testimator lgbm's best error=0.1335,\tbest estimator xgb_limitdepth's best error=0.1324\n",
      "[flaml.automl.logger: 07-22 14:09:56] {2219} INFO - iteration 102, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:09:57] {2392} INFO -  at 32.2s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator xgb_limitdepth's best error=0.1324\n",
      "[flaml.automl.logger: 07-22 14:09:57] {2219} INFO - iteration 103, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:09:58] {2392} INFO -  at 33.9s,\testimator catboost's best error=0.1308,\tbest estimator catboost's best error=0.1308\n",
      "[flaml.automl.logger: 07-22 14:09:58] {2219} INFO - iteration 104, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:09:59] {2392} INFO -  at 34.4s,\testimator lgbm's best error=0.1335,\tbest estimator catboost's best error=0.1308\n",
      "[flaml.automl.logger: 07-22 14:09:59] {2219} INFO - iteration 105, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:09:59] {2392} INFO -  at 34.7s,\testimator xgboost's best error=0.1335,\tbest estimator catboost's best error=0.1308\n",
      "[flaml.automl.logger: 07-22 14:09:59] {2219} INFO - iteration 106, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:09:59] {2392} INFO -  at 34.8s,\testimator lgbm's best error=0.1335,\tbest estimator catboost's best error=0.1308\n",
      "[flaml.automl.logger: 07-22 14:09:59] {2219} INFO - iteration 107, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:10:01] {2392} INFO -  at 36.7s,\testimator catboost's best error=0.1279,\tbest estimator catboost's best error=0.1279\n",
      "[flaml.automl.logger: 07-22 14:10:01] {2219} INFO - iteration 108, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:10:01] {2392} INFO -  at 37.1s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1279\n",
      "[flaml.automl.logger: 07-22 14:10:01] {2219} INFO - iteration 109, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:10:03] {2392} INFO -  at 39.1s,\testimator catboost's best error=0.1279,\tbest estimator catboost's best error=0.1279\n",
      "[flaml.automl.logger: 07-22 14:10:03] {2219} INFO - iteration 110, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:10:04] {2392} INFO -  at 39.4s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1279\n",
      "[flaml.automl.logger: 07-22 14:10:04] {2219} INFO - iteration 111, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:10:06] {2392} INFO -  at 41.6s,\testimator catboost's best error=0.1279,\tbest estimator catboost's best error=0.1279\n",
      "[flaml.automl.logger: 07-22 14:10:06] {2219} INFO - iteration 112, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:10:06] {2392} INFO -  at 41.8s,\testimator lgbm's best error=0.1335,\tbest estimator catboost's best error=0.1279\n",
      "[flaml.automl.logger: 07-22 14:10:06] {2219} INFO - iteration 113, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:10:06] {2392} INFO -  at 42.0s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1279\n",
      "[flaml.automl.logger: 07-22 14:10:06] {2219} INFO - iteration 114, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:10:07] {2392} INFO -  at 42.4s,\testimator xgboost's best error=0.1335,\tbest estimator catboost's best error=0.1279\n",
      "[flaml.automl.logger: 07-22 14:10:07] {2219} INFO - iteration 115, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:10:07] {2392} INFO -  at 42.6s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1279\n",
      "[flaml.automl.logger: 07-22 14:10:07] {2219} INFO - iteration 116, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:10:07] {2392} INFO -  at 42.8s,\testimator lgbm's best error=0.1335,\tbest estimator catboost's best error=0.1279\n",
      "[flaml.automl.logger: 07-22 14:10:07] {2219} INFO - iteration 117, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:10:07] {2392} INFO -  at 43.0s,\testimator lgbm's best error=0.1335,\tbest estimator catboost's best error=0.1279\n",
      "[flaml.automl.logger: 07-22 14:10:07] {2219} INFO - iteration 118, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:10:08] {2392} INFO -  at 43.5s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1279\n",
      "[flaml.automl.logger: 07-22 14:10:08] {2219} INFO - iteration 119, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:10:08] {2392} INFO -  at 44.1s,\testimator xgboost's best error=0.1335,\tbest estimator catboost's best error=0.1279\n",
      "[flaml.automl.logger: 07-22 14:10:08] {2219} INFO - iteration 120, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:10:09] {2392} INFO -  at 44.2s,\testimator lgbm's best error=0.1335,\tbest estimator catboost's best error=0.1279\n",
      "[flaml.automl.logger: 07-22 14:10:09] {2219} INFO - iteration 121, current learner extra_tree\n",
      "[flaml.automl.logger: 07-22 14:10:09] {2392} INFO -  at 44.6s,\testimator extra_tree's best error=0.1671,\tbest estimator catboost's best error=0.1279\n",
      "[flaml.automl.logger: 07-22 14:10:09] {2219} INFO - iteration 122, current learner extra_tree\n",
      "[flaml.automl.logger: 07-22 14:10:10] {2392} INFO -  at 45.2s,\testimator extra_tree's best error=0.1620,\tbest estimator catboost's best error=0.1279\n",
      "[flaml.automl.logger: 07-22 14:10:10] {2219} INFO - iteration 123, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:10:10] {2392} INFO -  at 45.5s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1279\n",
      "[flaml.automl.logger: 07-22 14:10:10] {2219} INFO - iteration 124, current learner extra_tree\n",
      "[flaml.automl.logger: 07-22 14:10:10] {2392} INFO -  at 46.2s,\testimator extra_tree's best error=0.1593,\tbest estimator catboost's best error=0.1279\n",
      "[flaml.automl.logger: 07-22 14:10:11] {2219} INFO - iteration 125, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:10:11] {2392} INFO -  at 46.4s,\testimator lgbm's best error=0.1335,\tbest estimator catboost's best error=0.1279\n",
      "[flaml.automl.logger: 07-22 14:10:11] {2219} INFO - iteration 126, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:10:11] {2392} INFO -  at 46.6s,\testimator lgbm's best error=0.1335,\tbest estimator catboost's best error=0.1279\n",
      "[flaml.automl.logger: 07-22 14:10:11] {2219} INFO - iteration 127, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:10:11] {2392} INFO -  at 46.7s,\testimator lgbm's best error=0.1335,\tbest estimator catboost's best error=0.1279\n",
      "[flaml.automl.logger: 07-22 14:10:11] {2219} INFO - iteration 128, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:10:11] {2392} INFO -  at 46.9s,\testimator lgbm's best error=0.1335,\tbest estimator catboost's best error=0.1279\n",
      "[flaml.automl.logger: 07-22 14:10:11] {2219} INFO - iteration 129, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:10:13] {2392} INFO -  at 48.7s,\testimator catboost's best error=0.1279,\tbest estimator catboost's best error=0.1279\n",
      "[flaml.automl.logger: 07-22 14:10:13] {2219} INFO - iteration 130, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:10:13] {2392} INFO -  at 49.0s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1279\n",
      "[flaml.automl.logger: 07-22 14:10:13] {2219} INFO - iteration 131, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:10:15] {2392} INFO -  at 51.1s,\testimator catboost's best error=0.1279,\tbest estimator catboost's best error=0.1279\n",
      "[flaml.automl.logger: 07-22 14:10:15] {2219} INFO - iteration 132, current learner lrl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sammi\\anaconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sammi\\anaconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sammi\\anaconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 07-22 14:10:16] {2392} INFO -  at 51.5s,\testimator lrl1's best error=0.3105,\tbest estimator catboost's best error=0.1279\n",
      "[flaml.automl.logger: 07-22 14:10:16] {2219} INFO - iteration 133, current learner lrl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sammi\\anaconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sammi\\anaconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sammi\\anaconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sammi\\anaconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sammi\\anaconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sammi\\anaconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 07-22 14:10:16] {2392} INFO -  at 51.9s,\testimator lrl1's best error=0.3099,\tbest estimator catboost's best error=0.1279\n",
      "[flaml.automl.logger: 07-22 14:10:16] {2219} INFO - iteration 134, current learner xgb_limitdepth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sammi\\anaconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 07-22 14:10:17] {2392} INFO -  at 52.3s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1279\n",
      "[flaml.automl.logger: 07-22 14:10:17] {2219} INFO - iteration 135, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:10:17] {2392} INFO -  at 52.5s,\testimator lgbm's best error=0.1335,\tbest estimator catboost's best error=0.1279\n",
      "[flaml.automl.logger: 07-22 14:10:17] {2219} INFO - iteration 136, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:10:19] {2392} INFO -  at 54.6s,\testimator catboost's best error=0.1279,\tbest estimator catboost's best error=0.1279\n",
      "[flaml.automl.logger: 07-22 14:10:19] {2219} INFO - iteration 137, current learner extra_tree\n",
      "[flaml.automl.logger: 07-22 14:10:20] {2392} INFO -  at 55.5s,\testimator extra_tree's best error=0.1593,\tbest estimator catboost's best error=0.1279\n",
      "[flaml.automl.logger: 07-22 14:10:20] {2219} INFO - iteration 138, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:10:20] {2392} INFO -  at 55.8s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1279\n",
      "[flaml.automl.logger: 07-22 14:10:20] {2219} INFO - iteration 139, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:10:20] {2392} INFO -  at 56.0s,\testimator xgboost's best error=0.1335,\tbest estimator catboost's best error=0.1279\n",
      "[flaml.automl.logger: 07-22 14:10:20] {2219} INFO - iteration 140, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:10:20] {2392} INFO -  at 56.2s,\testimator lgbm's best error=0.1335,\tbest estimator catboost's best error=0.1279\n",
      "[flaml.automl.logger: 07-22 14:10:20] {2219} INFO - iteration 141, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:10:21] {2392} INFO -  at 56.4s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1279\n",
      "[flaml.automl.logger: 07-22 14:10:21] {2219} INFO - iteration 142, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:10:21] {2392} INFO -  at 56.6s,\testimator lgbm's best error=0.1335,\tbest estimator catboost's best error=0.1279\n",
      "[flaml.automl.logger: 07-22 14:10:21] {2219} INFO - iteration 143, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:10:21] {2392} INFO -  at 56.8s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1279\n",
      "[flaml.automl.logger: 07-22 14:10:21] {2219} INFO - iteration 144, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:10:23] {2392} INFO -  at 58.6s,\testimator catboost's best error=0.1263,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:10:23] {2219} INFO - iteration 145, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:10:23] {2392} INFO -  at 59.0s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:10:23] {2219} INFO - iteration 146, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:10:24] {2392} INFO -  at 59.2s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:10:24] {2219} INFO - iteration 147, current learner extra_tree\n",
      "[flaml.automl.logger: 07-22 14:10:24] {2392} INFO -  at 59.6s,\testimator extra_tree's best error=0.1593,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:10:24] {2219} INFO - iteration 148, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:10:24] {2392} INFO -  at 59.8s,\testimator lgbm's best error=0.1335,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:10:24] {2219} INFO - iteration 149, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:10:24] {2392} INFO -  at 60.0s,\testimator lgbm's best error=0.1335,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:10:25] {2628} INFO - retrain catboost for 0.2s\n",
      "[flaml.automl.logger: 07-22 14:10:25] {2631} INFO - retrained model: <catboost.core.CatBoostClassifier object at 0x000001F5B642C310>\n",
      "[flaml.automl.logger: 07-22 14:10:25] {1931} INFO - fit succeeded\n",
      "[flaml.automl.logger: 07-22 14:10:25] {1932} INFO - Time taken to find the best model: 58.575722455978394\n"
     ]
    }
   ],
   "source": [
    "automl = AutoML()\n",
    "automl.fit(X_train, y_train, task=\"classification\", time_budget=60, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run this line to see what model it selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<flaml.automl.model.CatBoostEstimator at 0x1f5b1e240d0>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's evaluate this model and put the results into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy (training)</th>\n",
       "      <th>Accuracy (validation)</th>\n",
       "      <th>Precision (validation)</th>\n",
       "      <th>Recall (validation)</th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Auto ML - Default Parameters - Scoring on ROC AUC</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.801</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Accuracy (training)  \\\n",
       "Auto ML - Default Parameters - Scoring on ROC AUC                0.863   \n",
       "\n",
       "                                                   Accuracy (validation)  \\\n",
       "Auto ML - Default Parameters - Scoring on ROC AUC                  0.811   \n",
       "\n",
       "                                                   Precision (validation)  \\\n",
       "Auto ML - Default Parameters - Scoring on ROC AUC                   0.802   \n",
       "\n",
       "                                                   Recall (validation)  AUC  \\\n",
       "Auto ML - Default Parameters - Scoring on ROC AUC                  0.8  0.8   \n",
       "\n",
       "                                                      f1  FP  FN  \n",
       "Auto ML - Default Parameters - Scoring on ROC AUC  0.801  13  14  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train = automl.predict(X_train)\n",
    "y_pred_val = automl.predict(X_validate)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_validate, y_pred_val, labels=[0, 1]).ravel()\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "          'Accuracy (training)': np.mean(y_pred_train == y_train),\n",
    "          'Accuracy (validation)': np.mean(y_pred_val == y_validate),\n",
    "          'Precision (validation)': precision_score(y_validate, y_pred_val, average='macro'),\n",
    "          'Recall (validation)': recall_score(y_validate, y_pred_val, average='macro'),\n",
    "          \"AUC\": roc_auc_score(y_validate, y_pred_val),\n",
    "          \"f1\": f1_score(y_validate, y_pred_val, average='macro'),\n",
    "          \"FP\": fp,\n",
    "          \"FN\": fn\n",
    "\n",
    "          }, index=[\"Auto ML - Default Parameters - Scoring on ROC AUC\"]\n",
    ").round(3)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems like pretty reasonable performance, based on our previous interactions with the titanic dataset, though not as good as we've seen sometimes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a function that will allow us to quickly calculate and store metrics when assessing the `automl` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_ml_get_results(name):\n",
    "    y_pred_train = automl.predict(X_train)\n",
    "    y_pred_val = automl.predict(X_validate)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_validate, y_pred_val, labels=[0, 1]).ravel()\n",
    "\n",
    "    return pd.DataFrame({\n",
    "            'Accuracy (training)': np.mean(y_pred_train == y_train),\n",
    "            'Accuracy (validation)': np.mean(y_pred_val == y_validate),\n",
    "            'Precision (validation)': precision_score(y_validate, y_pred_val, average='macro'),\n",
    "            'Recall (validation)': recall_score(y_validate, y_pred_val, average='macro'),\n",
    "            \"AUC\": roc_auc_score(y_validate, y_pred_val),\n",
    "            \"f1\": f1_score(y_validate, y_pred_val, average='macro'),\n",
    "            \"FP\": fp,\n",
    "            \"FN\": fn\n",
    "\n",
    "            }, index=[name]\n",
    "    ).round(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 07-22 14:10:25] {1680} INFO - task = classification\n",
      "[flaml.automl.logger: 07-22 14:10:25] {1691} INFO - Evaluation method: cv\n",
      "[flaml.automl.logger: 07-22 14:10:25] {1789} INFO - Minimizing error metric: 1-f1\n",
      "[flaml.automl.logger: 07-22 14:10:25] {1901} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'lrl1']\n",
      "[flaml.automl.logger: 07-22 14:10:25] {2219} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:10:25] {2345} INFO - Estimated sufficient time budget=3869s. Estimated necessary time budget=95s.\n",
      "[flaml.automl.logger: 07-22 14:10:25] {2392} INFO -  at 0.5s,\testimator lgbm's best error=0.4095,\tbest estimator lgbm's best error=0.4095\n",
      "[flaml.automl.logger: 07-22 14:10:25] {2219} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:10:25] {2392} INFO -  at 0.6s,\testimator lgbm's best error=0.4095,\tbest estimator lgbm's best error=0.4095\n",
      "[flaml.automl.logger: 07-22 14:10:25] {2219} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:10:25] {2392} INFO -  at 0.8s,\testimator lgbm's best error=0.3646,\tbest estimator lgbm's best error=0.3646\n",
      "[flaml.automl.logger: 07-22 14:10:25] {2219} INFO - iteration 3, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:10:26] {2392} INFO -  at 0.9s,\testimator lgbm's best error=0.2907,\tbest estimator lgbm's best error=0.2907\n",
      "[flaml.automl.logger: 07-22 14:10:26] {2219} INFO - iteration 4, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:10:26] {2392} INFO -  at 1.0s,\testimator lgbm's best error=0.2907,\tbest estimator lgbm's best error=0.2907\n",
      "[flaml.automl.logger: 07-22 14:10:26] {2219} INFO - iteration 5, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:10:26] {2392} INFO -  at 1.1s,\testimator lgbm's best error=0.2907,\tbest estimator lgbm's best error=0.2907\n",
      "[flaml.automl.logger: 07-22 14:10:26] {2219} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:10:26] {2392} INFO -  at 1.2s,\testimator lgbm's best error=0.2907,\tbest estimator lgbm's best error=0.2907\n",
      "[flaml.automl.logger: 07-22 14:10:26] {2219} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:10:26] {2392} INFO -  at 1.4s,\testimator lgbm's best error=0.2872,\tbest estimator lgbm's best error=0.2872\n",
      "[flaml.automl.logger: 07-22 14:10:26] {2219} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:10:26] {2392} INFO -  at 1.5s,\testimator lgbm's best error=0.2872,\tbest estimator lgbm's best error=0.2872\n",
      "[flaml.automl.logger: 07-22 14:10:26] {2219} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:10:26] {2392} INFO -  at 1.7s,\testimator lgbm's best error=0.2872,\tbest estimator lgbm's best error=0.2872\n",
      "[flaml.automl.logger: 07-22 14:10:26] {2219} INFO - iteration 10, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:10:26] {2392} INFO -  at 1.8s,\testimator lgbm's best error=0.2872,\tbest estimator lgbm's best error=0.2872\n",
      "[flaml.automl.logger: 07-22 14:10:26] {2219} INFO - iteration 11, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:10:27] {2392} INFO -  at 2.0s,\testimator lgbm's best error=0.2872,\tbest estimator lgbm's best error=0.2872\n",
      "[flaml.automl.logger: 07-22 14:10:27] {2219} INFO - iteration 12, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:10:27] {2392} INFO -  at 2.2s,\testimator xgboost's best error=0.4095,\tbest estimator lgbm's best error=0.2872\n",
      "[flaml.automl.logger: 07-22 14:10:27] {2219} INFO - iteration 13, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:10:27] {2392} INFO -  at 2.4s,\testimator xgboost's best error=0.4095,\tbest estimator lgbm's best error=0.2872\n",
      "[flaml.automl.logger: 07-22 14:10:27] {2219} INFO - iteration 14, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:10:27] {2392} INFO -  at 2.5s,\testimator lgbm's best error=0.2872,\tbest estimator lgbm's best error=0.2872\n",
      "[flaml.automl.logger: 07-22 14:10:27] {2219} INFO - iteration 15, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:10:27] {2392} INFO -  at 2.6s,\testimator xgboost's best error=0.3560,\tbest estimator lgbm's best error=0.2872\n",
      "[flaml.automl.logger: 07-22 14:10:27] {2219} INFO - iteration 16, current learner extra_tree\n",
      "[flaml.automl.logger: 07-22 14:10:28] {2392} INFO -  at 3.0s,\testimator extra_tree's best error=0.3919,\tbest estimator lgbm's best error=0.2872\n",
      "[flaml.automl.logger: 07-22 14:10:28] {2219} INFO - iteration 17, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:10:28] {2392} INFO -  at 3.2s,\testimator lgbm's best error=0.2872,\tbest estimator lgbm's best error=0.2872\n",
      "[flaml.automl.logger: 07-22 14:10:28] {2219} INFO - iteration 18, current learner extra_tree\n",
      "[flaml.automl.logger: 07-22 14:10:29] {2392} INFO -  at 4.0s,\testimator extra_tree's best error=0.3919,\tbest estimator lgbm's best error=0.2872\n",
      "[flaml.automl.logger: 07-22 14:10:29] {2219} INFO - iteration 19, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:10:29] {2392} INFO -  at 4.5s,\testimator rf's best error=0.4009,\tbest estimator lgbm's best error=0.2872\n",
      "[flaml.automl.logger: 07-22 14:10:29] {2219} INFO - iteration 20, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:10:30] {2392} INFO -  at 5.4s,\testimator rf's best error=0.4009,\tbest estimator lgbm's best error=0.2872\n",
      "[flaml.automl.logger: 07-22 14:10:30] {2219} INFO - iteration 21, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:10:30] {2392} INFO -  at 5.6s,\testimator xgboost's best error=0.3560,\tbest estimator lgbm's best error=0.2872\n",
      "[flaml.automl.logger: 07-22 14:10:30] {2219} INFO - iteration 22, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:10:30] {2392} INFO -  at 5.8s,\testimator lgbm's best error=0.2748,\tbest estimator lgbm's best error=0.2748\n",
      "[flaml.automl.logger: 07-22 14:10:30] {2219} INFO - iteration 23, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:10:31] {2392} INFO -  at 6.2s,\testimator lgbm's best error=0.2748,\tbest estimator lgbm's best error=0.2748\n",
      "[flaml.automl.logger: 07-22 14:10:31] {2219} INFO - iteration 24, current learner extra_tree\n",
      "[flaml.automl.logger: 07-22 14:10:31] {2392} INFO -  at 6.7s,\testimator extra_tree's best error=0.3919,\tbest estimator lgbm's best error=0.2748\n",
      "[flaml.automl.logger: 07-22 14:10:31] {2219} INFO - iteration 25, current learner extra_tree\n",
      "[flaml.automl.logger: 07-22 14:10:32] {2392} INFO -  at 7.6s,\testimator extra_tree's best error=0.3746,\tbest estimator lgbm's best error=0.2748\n",
      "[flaml.automl.logger: 07-22 14:10:32] {2219} INFO - iteration 26, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:10:32] {2392} INFO -  at 7.8s,\testimator lgbm's best error=0.2748,\tbest estimator lgbm's best error=0.2748\n",
      "[flaml.automl.logger: 07-22 14:10:32] {2219} INFO - iteration 27, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:10:33] {2392} INFO -  at 8.2s,\testimator rf's best error=0.3643,\tbest estimator lgbm's best error=0.2748\n",
      "[flaml.automl.logger: 07-22 14:10:33] {2219} INFO - iteration 28, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:10:33] {2392} INFO -  at 8.4s,\testimator xgboost's best error=0.2984,\tbest estimator lgbm's best error=0.2748\n",
      "[flaml.automl.logger: 07-22 14:10:33] {2219} INFO - iteration 29, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:10:33] {2392} INFO -  at 8.6s,\testimator xgboost's best error=0.2937,\tbest estimator lgbm's best error=0.2748\n",
      "[flaml.automl.logger: 07-22 14:10:33] {2219} INFO - iteration 30, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:10:33] {2392} INFO -  at 8.7s,\testimator lgbm's best error=0.2748,\tbest estimator lgbm's best error=0.2748\n",
      "[flaml.automl.logger: 07-22 14:10:33] {2219} INFO - iteration 31, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:10:34] {2392} INFO -  at 9.0s,\testimator lgbm's best error=0.2748,\tbest estimator lgbm's best error=0.2748\n",
      "[flaml.automl.logger: 07-22 14:10:34] {2219} INFO - iteration 32, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:10:34] {2392} INFO -  at 9.3s,\testimator lgbm's best error=0.2748,\tbest estimator lgbm's best error=0.2748\n",
      "[flaml.automl.logger: 07-22 14:10:34] {2219} INFO - iteration 33, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:10:34] {2392} INFO -  at 9.4s,\testimator xgboost's best error=0.2937,\tbest estimator lgbm's best error=0.2748\n",
      "[flaml.automl.logger: 07-22 14:10:34] {2219} INFO - iteration 34, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:10:34] {2392} INFO -  at 9.6s,\testimator lgbm's best error=0.2748,\tbest estimator lgbm's best error=0.2748\n",
      "[flaml.automl.logger: 07-22 14:10:34] {2219} INFO - iteration 35, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:10:34] {2392} INFO -  at 9.7s,\testimator lgbm's best error=0.2748,\tbest estimator lgbm's best error=0.2748\n",
      "[flaml.automl.logger: 07-22 14:10:34] {2219} INFO - iteration 36, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:10:35] {2392} INFO -  at 9.9s,\testimator xgboost's best error=0.2937,\tbest estimator lgbm's best error=0.2748\n",
      "[flaml.automl.logger: 07-22 14:10:35] {2219} INFO - iteration 37, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:10:35] {2392} INFO -  at 10.0s,\testimator lgbm's best error=0.2739,\tbest estimator lgbm's best error=0.2739\n",
      "[flaml.automl.logger: 07-22 14:10:35] {2219} INFO - iteration 38, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:10:36] {2392} INFO -  at 11.0s,\testimator rf's best error=0.3115,\tbest estimator lgbm's best error=0.2739\n",
      "[flaml.automl.logger: 07-22 14:10:36] {2219} INFO - iteration 39, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:10:36] {2392} INFO -  at 11.1s,\testimator lgbm's best error=0.2739,\tbest estimator lgbm's best error=0.2739\n",
      "[flaml.automl.logger: 07-22 14:10:36] {2219} INFO - iteration 40, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:10:36] {2392} INFO -  at 11.6s,\testimator rf's best error=0.3115,\tbest estimator lgbm's best error=0.2739\n",
      "[flaml.automl.logger: 07-22 14:10:36] {2219} INFO - iteration 41, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:10:36] {2392} INFO -  at 11.8s,\testimator xgboost's best error=0.2831,\tbest estimator lgbm's best error=0.2739\n",
      "[flaml.automl.logger: 07-22 14:10:36] {2219} INFO - iteration 42, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:10:37] {2392} INFO -  at 12.0s,\testimator lgbm's best error=0.2739,\tbest estimator lgbm's best error=0.2739\n",
      "[flaml.automl.logger: 07-22 14:10:37] {2219} INFO - iteration 43, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:10:37] {2392} INFO -  at 12.2s,\testimator xgboost's best error=0.2831,\tbest estimator lgbm's best error=0.2739\n",
      "[flaml.automl.logger: 07-22 14:10:37] {2219} INFO - iteration 44, current learner extra_tree\n",
      "[flaml.automl.logger: 07-22 14:10:37] {2392} INFO -  at 12.6s,\testimator extra_tree's best error=0.3746,\tbest estimator lgbm's best error=0.2739\n",
      "[flaml.automl.logger: 07-22 14:10:37] {2219} INFO - iteration 45, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:10:38] {2392} INFO -  at 12.8s,\testimator xgboost's best error=0.2831,\tbest estimator lgbm's best error=0.2739\n",
      "[flaml.automl.logger: 07-22 14:10:38] {2219} INFO - iteration 46, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:10:38] {2392} INFO -  at 13.0s,\testimator lgbm's best error=0.2739,\tbest estimator lgbm's best error=0.2739\n",
      "[flaml.automl.logger: 07-22 14:10:38] {2219} INFO - iteration 47, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:10:38] {2392} INFO -  at 13.4s,\testimator xgboost's best error=0.2831,\tbest estimator lgbm's best error=0.2739\n",
      "[flaml.automl.logger: 07-22 14:10:38] {2219} INFO - iteration 48, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:10:38] {2392} INFO -  at 13.6s,\testimator lgbm's best error=0.2739,\tbest estimator lgbm's best error=0.2739\n",
      "[flaml.automl.logger: 07-22 14:10:38] {2219} INFO - iteration 49, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:10:39] {2392} INFO -  at 14.6s,\testimator rf's best error=0.3115,\tbest estimator lgbm's best error=0.2739\n",
      "[flaml.automl.logger: 07-22 14:10:39] {2219} INFO - iteration 50, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:10:39] {2392} INFO -  at 14.8s,\testimator xgboost's best error=0.2831,\tbest estimator lgbm's best error=0.2739\n",
      "[flaml.automl.logger: 07-22 14:10:39] {2219} INFO - iteration 51, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:10:40] {2392} INFO -  at 15.0s,\testimator lgbm's best error=0.2739,\tbest estimator lgbm's best error=0.2739\n",
      "[flaml.automl.logger: 07-22 14:10:40] {2219} INFO - iteration 52, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:10:40] {2392} INFO -  at 15.1s,\testimator lgbm's best error=0.2739,\tbest estimator lgbm's best error=0.2739\n",
      "[flaml.automl.logger: 07-22 14:10:40] {2219} INFO - iteration 53, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:10:40] {2392} INFO -  at 15.3s,\testimator lgbm's best error=0.2739,\tbest estimator lgbm's best error=0.2739\n",
      "[flaml.automl.logger: 07-22 14:10:40] {2219} INFO - iteration 54, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:10:40] {2392} INFO -  at 15.5s,\testimator lgbm's best error=0.2739,\tbest estimator lgbm's best error=0.2739\n",
      "[flaml.automl.logger: 07-22 14:10:40] {2219} INFO - iteration 55, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:10:41] {2392} INFO -  at 16.0s,\testimator rf's best error=0.3115,\tbest estimator lgbm's best error=0.2739\n",
      "[flaml.automl.logger: 07-22 14:10:41] {2219} INFO - iteration 56, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:10:41] {2392} INFO -  at 16.2s,\testimator lgbm's best error=0.2739,\tbest estimator lgbm's best error=0.2739\n",
      "[flaml.automl.logger: 07-22 14:10:41] {2219} INFO - iteration 57, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:10:41] {2392} INFO -  at 16.3s,\testimator lgbm's best error=0.2739,\tbest estimator lgbm's best error=0.2739\n",
      "[flaml.automl.logger: 07-22 14:10:41] {2219} INFO - iteration 58, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:10:42] {2392} INFO -  at 16.8s,\testimator rf's best error=0.3115,\tbest estimator lgbm's best error=0.2739\n",
      "[flaml.automl.logger: 07-22 14:10:42] {2219} INFO - iteration 59, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:10:42] {2392} INFO -  at 17.3s,\testimator lgbm's best error=0.2739,\tbest estimator lgbm's best error=0.2739\n",
      "[flaml.automl.logger: 07-22 14:10:42] {2219} INFO - iteration 60, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:10:43] {2392} INFO -  at 18.3s,\testimator rf's best error=0.3115,\tbest estimator lgbm's best error=0.2739\n",
      "[flaml.automl.logger: 07-22 14:10:43] {2219} INFO - iteration 61, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:10:43] {2392} INFO -  at 18.4s,\testimator lgbm's best error=0.2739,\tbest estimator lgbm's best error=0.2739\n",
      "[flaml.automl.logger: 07-22 14:10:43] {2219} INFO - iteration 62, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:10:44] {2392} INFO -  at 19.5s,\testimator rf's best error=0.3115,\tbest estimator lgbm's best error=0.2739\n",
      "[flaml.automl.logger: 07-22 14:10:44] {2219} INFO - iteration 63, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:10:44] {2392} INFO -  at 19.7s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:10:44] {2219} INFO - iteration 64, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:10:45] {2392} INFO -  at 20.2s,\testimator rf's best error=0.2901,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:10:45] {2219} INFO - iteration 65, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:10:45] {2392} INFO -  at 20.5s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:10:45] {2219} INFO - iteration 66, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:10:45] {2392} INFO -  at 20.7s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:10:45] {2219} INFO - iteration 67, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:10:46] {2392} INFO -  at 20.9s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:10:46] {2219} INFO - iteration 68, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:10:46] {2392} INFO -  at 21.4s,\testimator rf's best error=0.2826,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:10:46] {2219} INFO - iteration 69, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:10:46] {2392} INFO -  at 21.7s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:10:46] {2219} INFO - iteration 70, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:10:47] {2392} INFO -  at 21.8s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:10:47] {2219} INFO - iteration 71, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:10:47] {2392} INFO -  at 22.0s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:10:47] {2219} INFO - iteration 72, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:10:47] {2392} INFO -  at 22.2s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:10:47] {2219} INFO - iteration 73, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:10:47] {2392} INFO -  at 22.4s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:10:47] {2219} INFO - iteration 74, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:10:47] {2392} INFO -  at 22.5s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:10:47] {2219} INFO - iteration 75, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:10:48] {2392} INFO -  at 23.1s,\testimator rf's best error=0.2826,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:10:48] {2219} INFO - iteration 76, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:10:48] {2392} INFO -  at 23.6s,\testimator rf's best error=0.2825,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:10:48] {2219} INFO - iteration 77, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:10:48] {2392} INFO -  at 23.8s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:10:48] {2219} INFO - iteration 78, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:10:49] {2392} INFO -  at 24.0s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:10:49] {2219} INFO - iteration 79, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:10:49] {2392} INFO -  at 24.1s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:10:49] {2219} INFO - iteration 80, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:10:49] {2392} INFO -  at 24.4s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:10:49] {2219} INFO - iteration 81, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:10:49] {2392} INFO -  at 24.5s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:10:49] {2219} INFO - iteration 82, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:10:49] {2392} INFO -  at 24.7s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:10:49] {2219} INFO - iteration 83, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:10:50] {2392} INFO -  at 25.0s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:10:50] {2219} INFO - iteration 84, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:10:50] {2392} INFO -  at 25.2s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:10:50] {2219} INFO - iteration 85, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:10:50] {2392} INFO -  at 25.3s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:10:50] {2219} INFO - iteration 86, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:10:50] {2392} INFO -  at 25.5s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:10:50] {2219} INFO - iteration 87, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:10:50] {2392} INFO -  at 25.7s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:10:50] {2219} INFO - iteration 88, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:10:51] {2392} INFO -  at 25.9s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:10:51] {2219} INFO - iteration 89, current learner extra_tree\n",
      "[flaml.automl.logger: 07-22 14:10:52] {2392} INFO -  at 26.9s,\testimator extra_tree's best error=0.3746,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:10:52] {2219} INFO - iteration 90, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:10:52] {2392} INFO -  at 27.1s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:10:52] {2219} INFO - iteration 91, current learner extra_tree\n",
      "[flaml.automl.logger: 07-22 14:10:52] {2392} INFO -  at 27.7s,\testimator extra_tree's best error=0.3746,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:10:52] {2219} INFO - iteration 92, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:10:53] {2392} INFO -  at 27.9s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:10:53] {2219} INFO - iteration 93, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:10:53] {2392} INFO -  at 28.1s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:10:53] {2219} INFO - iteration 94, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:10:53] {2392} INFO -  at 28.3s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:10:53] {2219} INFO - iteration 95, current learner extra_tree\n",
      "[flaml.automl.logger: 07-22 14:10:53] {2392} INFO -  at 28.8s,\testimator extra_tree's best error=0.3746,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:10:53] {2219} INFO - iteration 96, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:10:54] {2392} INFO -  at 29.1s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:10:54] {2219} INFO - iteration 97, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:10:54] {2392} INFO -  at 29.2s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:10:54] {2219} INFO - iteration 98, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:10:54] {2392} INFO -  at 29.4s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:10:54] {2219} INFO - iteration 99, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:10:54] {2392} INFO -  at 29.6s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:10:54] {2219} INFO - iteration 100, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:10:54] {2392} INFO -  at 29.7s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:10:54] {2219} INFO - iteration 101, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:10:55] {2392} INFO -  at 29.9s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:10:55] {2219} INFO - iteration 102, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:10:56] {2392} INFO -  at 31.7s,\testimator catboost's best error=0.2817,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:10:56] {2219} INFO - iteration 103, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:10:59] {2392} INFO -  at 34.2s,\testimator catboost's best error=0.2817,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:10:59] {2219} INFO - iteration 104, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:11:01] {2392} INFO -  at 36.0s,\testimator catboost's best error=0.2817,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:11:01] {2219} INFO - iteration 105, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:11:03] {2392} INFO -  at 38.4s,\testimator catboost's best error=0.2817,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:11:03] {2219} INFO - iteration 106, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:03] {2392} INFO -  at 38.6s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:11:03] {2219} INFO - iteration 107, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:03] {2392} INFO -  at 38.8s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:11:03] {2219} INFO - iteration 108, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:11:05] {2392} INFO -  at 40.3s,\testimator catboost's best error=0.2765,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:11:05] {2219} INFO - iteration 109, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:05] {2392} INFO -  at 40.5s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:11:05] {2219} INFO - iteration 110, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:05] {2392} INFO -  at 40.6s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:11:05] {2219} INFO - iteration 111, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:11:08] {2392} INFO -  at 42.9s,\testimator catboost's best error=0.2765,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:11:08] {2219} INFO - iteration 112, current learner extra_tree\n",
      "[flaml.automl.logger: 07-22 14:11:08] {2392} INFO -  at 43.8s,\testimator extra_tree's best error=0.3746,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:11:08] {2219} INFO - iteration 113, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:09] {2392} INFO -  at 44.1s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:11:09] {2219} INFO - iteration 114, current learner extra_tree\n",
      "[flaml.automl.logger: 07-22 14:11:10] {2392} INFO -  at 45.1s,\testimator extra_tree's best error=0.3746,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:11:10] {2219} INFO - iteration 115, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:10] {2392} INFO -  at 45.3s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:11:10] {2219} INFO - iteration 116, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:10] {2392} INFO -  at 45.5s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:11:10] {2219} INFO - iteration 117, current learner extra_tree\n",
      "[flaml.automl.logger: 07-22 14:11:11] {2392} INFO -  at 46.0s,\testimator extra_tree's best error=0.3105,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:11:11] {2219} INFO - iteration 118, current learner extra_tree\n",
      "[flaml.automl.logger: 07-22 14:11:11] {2392} INFO -  at 46.6s,\testimator extra_tree's best error=0.3105,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:11:11] {2219} INFO - iteration 119, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:11:12] {2392} INFO -  at 47.8s,\testimator catboost's best error=0.2765,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:11:13] {2219} INFO - iteration 120, current learner extra_tree\n",
      "[flaml.automl.logger: 07-22 14:11:13] {2392} INFO -  at 48.4s,\testimator extra_tree's best error=0.3105,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:11:13] {2219} INFO - iteration 121, current learner extra_tree\n",
      "[flaml.automl.logger: 07-22 14:11:14] {2392} INFO -  at 48.9s,\testimator extra_tree's best error=0.3105,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:11:14] {2219} INFO - iteration 122, current learner extra_tree\n",
      "[flaml.automl.logger: 07-22 14:11:14] {2392} INFO -  at 49.5s,\testimator extra_tree's best error=0.3105,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:11:14] {2219} INFO - iteration 123, current learner extra_tree\n",
      "[flaml.automl.logger: 07-22 14:11:15] {2392} INFO -  at 50.0s,\testimator extra_tree's best error=0.3105,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:11:15] {2219} INFO - iteration 124, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:15] {2392} INFO -  at 50.2s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:11:15] {2219} INFO - iteration 125, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:11:16] {2392} INFO -  at 51.4s,\testimator catboost's best error=0.2765,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:11:16] {2219} INFO - iteration 126, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:11:19] {2392} INFO -  at 54.2s,\testimator catboost's best error=0.2765,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:11:19] {2219} INFO - iteration 127, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:11:21] {2392} INFO -  at 56.6s,\testimator catboost's best error=0.2697,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:11:21] {2219} INFO - iteration 128, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:22] {2392} INFO -  at 56.9s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:11:22] {2219} INFO - iteration 129, current learner extra_tree\n",
      "[flaml.automl.logger: 07-22 14:11:22] {2392} INFO -  at 57.4s,\testimator extra_tree's best error=0.3095,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:11:22] {2219} INFO - iteration 130, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:22] {2392} INFO -  at 57.7s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:11:22] {2219} INFO - iteration 131, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:23] {2392} INFO -  at 57.9s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:11:23] {2219} INFO - iteration 132, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:23] {2392} INFO -  at 58.1s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:11:23] {2219} INFO - iteration 133, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:23] {2392} INFO -  at 58.3s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:11:23] {2219} INFO - iteration 134, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:23] {2392} INFO -  at 58.4s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:11:23] {2219} INFO - iteration 135, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:23] {2392} INFO -  at 58.6s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:11:23] {2219} INFO - iteration 136, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:23] {2392} INFO -  at 58.8s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:11:23] {2219} INFO - iteration 137, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:24] {2392} INFO -  at 59.0s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:11:24] {2219} INFO - iteration 138, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:24] {2392} INFO -  at 59.2s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:11:24] {2219} INFO - iteration 139, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:24] {2392} INFO -  at 59.4s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:11:24] {2219} INFO - iteration 140, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:24] {2392} INFO -  at 59.6s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:11:24] {2219} INFO - iteration 141, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:24] {2392} INFO -  at 59.8s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:11:24] {2219} INFO - iteration 142, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:25] {2392} INFO -  at 59.9s,\testimator xgboost's best error=0.2615,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:11:25] {2219} INFO - iteration 143, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:11:25] {2392} INFO -  at 60.0s,\testimator xgb_limitdepth's best error=0.3910,\tbest estimator xgboost's best error=0.2615\n",
      "[flaml.automl.logger: 07-22 14:11:25] {2628} INFO - retrain xgboost for 0.0s\n",
      "[flaml.automl.logger: 07-22 14:11:25] {2631} INFO - retrained model: XGBClassifier(base_score=None, booster=None, callbacks=[],\n",
      "              colsample_bylevel=0.9628630562654891, colsample_bynode=None,\n",
      "              colsample_bytree=0.9458221079928131, device=None,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=None, feature_types=None, gamma=None,\n",
      "              grow_policy='lossguide', importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=1.0, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=0, max_leaves=6,\n",
      "              min_child_weight=1.1104804410139288, missing=nan,\n",
      "              monotone_constraints=None, multi_strategy=None, n_estimators=4,\n",
      "              n_jobs=-1, num_parallel_tree=None, random_state=None, ...)\n",
      "[flaml.automl.logger: 07-22 14:11:25] {1931} INFO - fit succeeded\n",
      "[flaml.automl.logger: 07-22 14:11:25] {1932} INFO - Time taken to find the best model: 19.729206085205078\n"
     ]
    }
   ],
   "source": [
    "automl = AutoML()\n",
    "automl.fit(X_train, y_train, task=\"classification\", time_budget=60,\n",
    "           metric=\"f1\", seed=42)\n",
    "results_df = pd.concat(\n",
    "    [results_df,\n",
    "    auto_ml_get_results(name=\"Auto ML - Scoring on f1\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 07-22 14:11:25] {1680} INFO - task = classification\n",
      "[flaml.automl.logger: 07-22 14:11:25] {1691} INFO - Evaluation method: cv\n",
      "[flaml.automl.logger: 07-22 14:11:25] {1789} INFO - Minimizing error metric: 1-roc_auc\n",
      "[flaml.automl.logger: 07-22 14:11:25] {1901} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'lrl1']\n",
      "[flaml.automl.logger: 07-22 14:11:25] {2219} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:11:25] {2345} INFO - Estimated sufficient time budget=2770s. Estimated necessary time budget=68s.\n",
      "[flaml.automl.logger: 07-22 14:11:25] {2392} INFO -  at 0.3s,\testimator lgbm's best error=0.1860,\tbest estimator lgbm's best error=0.1860\n",
      "[flaml.automl.logger: 07-22 14:11:25] {2219} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:11:25] {2392} INFO -  at 0.5s,\testimator lgbm's best error=0.1614,\tbest estimator lgbm's best error=0.1614\n",
      "[flaml.automl.logger: 07-22 14:11:25] {2219} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:11:25] {2392} INFO -  at 0.6s,\testimator lgbm's best error=0.1516,\tbest estimator lgbm's best error=0.1516\n",
      "[flaml.automl.logger: 07-22 14:11:25] {2219} INFO - iteration 3, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:11:26] {2392} INFO -  at 0.7s,\testimator lgbm's best error=0.1468,\tbest estimator lgbm's best error=0.1468\n",
      "[flaml.automl.logger: 07-22 14:11:26] {2219} INFO - iteration 4, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:11:26] {2392} INFO -  at 0.8s,\testimator lgbm's best error=0.1460,\tbest estimator lgbm's best error=0.1460\n",
      "[flaml.automl.logger: 07-22 14:11:26] {2219} INFO - iteration 5, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:11:26] {2392} INFO -  at 0.9s,\testimator lgbm's best error=0.1460,\tbest estimator lgbm's best error=0.1460\n",
      "[flaml.automl.logger: 07-22 14:11:26] {2219} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:11:26] {2392} INFO -  at 1.0s,\testimator lgbm's best error=0.1460,\tbest estimator lgbm's best error=0.1460\n",
      "[flaml.automl.logger: 07-22 14:11:26] {2219} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:11:26] {2392} INFO -  at 1.2s,\testimator lgbm's best error=0.1416,\tbest estimator lgbm's best error=0.1416\n",
      "[flaml.automl.logger: 07-22 14:11:26] {2219} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:11:26] {2392} INFO -  at 1.3s,\testimator lgbm's best error=0.1416,\tbest estimator lgbm's best error=0.1416\n",
      "[flaml.automl.logger: 07-22 14:11:26] {2219} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:11:26] {2392} INFO -  at 1.4s,\testimator lgbm's best error=0.1416,\tbest estimator lgbm's best error=0.1416\n",
      "[flaml.automl.logger: 07-22 14:11:26] {2219} INFO - iteration 10, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:11:27] {2392} INFO -  at 1.8s,\testimator lgbm's best error=0.1416,\tbest estimator lgbm's best error=0.1416\n",
      "[flaml.automl.logger: 07-22 14:11:27] {2219} INFO - iteration 11, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:27] {2392} INFO -  at 2.0s,\testimator xgboost's best error=0.1834,\tbest estimator lgbm's best error=0.1416\n",
      "[flaml.automl.logger: 07-22 14:11:27] {2219} INFO - iteration 12, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:27] {2392} INFO -  at 2.4s,\testimator xgboost's best error=0.1834,\tbest estimator lgbm's best error=0.1416\n",
      "[flaml.automl.logger: 07-22 14:11:27] {2219} INFO - iteration 13, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:27] {2392} INFO -  at 2.6s,\testimator xgboost's best error=0.1482,\tbest estimator lgbm's best error=0.1416\n",
      "[flaml.automl.logger: 07-22 14:11:27] {2219} INFO - iteration 14, current learner extra_tree\n",
      "[flaml.automl.logger: 07-22 14:11:28] {2392} INFO -  at 3.0s,\testimator extra_tree's best error=0.1707,\tbest estimator lgbm's best error=0.1416\n",
      "[flaml.automl.logger: 07-22 14:11:28] {2219} INFO - iteration 15, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:11:28] {2392} INFO -  at 3.2s,\testimator lgbm's best error=0.1383,\tbest estimator lgbm's best error=0.1383\n",
      "[flaml.automl.logger: 07-22 14:11:28] {2219} INFO - iteration 16, current learner extra_tree\n",
      "[flaml.automl.logger: 07-22 14:11:29] {2392} INFO -  at 4.0s,\testimator extra_tree's best error=0.1707,\tbest estimator lgbm's best error=0.1383\n",
      "[flaml.automl.logger: 07-22 14:11:29] {2219} INFO - iteration 17, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:11:29] {2392} INFO -  at 4.6s,\testimator rf's best error=0.1907,\tbest estimator lgbm's best error=0.1383\n",
      "[flaml.automl.logger: 07-22 14:11:29] {2219} INFO - iteration 18, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:11:30] {2392} INFO -  at 4.8s,\testimator lgbm's best error=0.1383,\tbest estimator lgbm's best error=0.1383\n",
      "[flaml.automl.logger: 07-22 14:11:30] {2219} INFO - iteration 19, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:30] {2392} INFO -  at 4.9s,\testimator xgboost's best error=0.1465,\tbest estimator lgbm's best error=0.1383\n",
      "[flaml.automl.logger: 07-22 14:11:30] {2219} INFO - iteration 20, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:11:31] {2392} INFO -  at 5.8s,\testimator rf's best error=0.1907,\tbest estimator lgbm's best error=0.1383\n",
      "[flaml.automl.logger: 07-22 14:11:31] {2219} INFO - iteration 21, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:11:31] {2392} INFO -  at 6.4s,\testimator rf's best error=0.1598,\tbest estimator lgbm's best error=0.1383\n",
      "[flaml.automl.logger: 07-22 14:11:31] {2219} INFO - iteration 22, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:11:31] {2392} INFO -  at 6.6s,\testimator lgbm's best error=0.1383,\tbest estimator lgbm's best error=0.1383\n",
      "[flaml.automl.logger: 07-22 14:11:31] {2219} INFO - iteration 23, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:11:32] {2392} INFO -  at 6.8s,\testimator lgbm's best error=0.1383,\tbest estimator lgbm's best error=0.1383\n",
      "[flaml.automl.logger: 07-22 14:11:32] {2219} INFO - iteration 24, current learner extra_tree\n",
      "[flaml.automl.logger: 07-22 14:11:32] {2392} INFO -  at 7.2s,\testimator extra_tree's best error=0.1707,\tbest estimator lgbm's best error=0.1383\n",
      "[flaml.automl.logger: 07-22 14:11:32] {2219} INFO - iteration 25, current learner extra_tree\n",
      "[flaml.automl.logger: 07-22 14:11:33] {2392} INFO -  at 8.1s,\testimator extra_tree's best error=0.1679,\tbest estimator lgbm's best error=0.1383\n",
      "[flaml.automl.logger: 07-22 14:11:33] {2219} INFO - iteration 26, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:11:33] {2392} INFO -  at 8.4s,\testimator lgbm's best error=0.1383,\tbest estimator lgbm's best error=0.1383\n",
      "[flaml.automl.logger: 07-22 14:11:33] {2219} INFO - iteration 27, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:11:34] {2392} INFO -  at 9.1s,\testimator rf's best error=0.1540,\tbest estimator lgbm's best error=0.1383\n",
      "[flaml.automl.logger: 07-22 14:11:34] {2219} INFO - iteration 28, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:34] {2392} INFO -  at 9.3s,\testimator xgboost's best error=0.1426,\tbest estimator lgbm's best error=0.1383\n",
      "[flaml.automl.logger: 07-22 14:11:34] {2219} INFO - iteration 29, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:34] {2392} INFO -  at 9.4s,\testimator xgboost's best error=0.1426,\tbest estimator lgbm's best error=0.1383\n",
      "[flaml.automl.logger: 07-22 14:11:34] {2219} INFO - iteration 30, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:11:34] {2392} INFO -  at 9.5s,\testimator lgbm's best error=0.1383,\tbest estimator lgbm's best error=0.1383\n",
      "[flaml.automl.logger: 07-22 14:11:34] {2219} INFO - iteration 31, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:11:34] {2392} INFO -  at 9.6s,\testimator lgbm's best error=0.1383,\tbest estimator lgbm's best error=0.1383\n",
      "[flaml.automl.logger: 07-22 14:11:34] {2219} INFO - iteration 32, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:11:35] {2392} INFO -  at 9.9s,\testimator lgbm's best error=0.1383,\tbest estimator lgbm's best error=0.1383\n",
      "[flaml.automl.logger: 07-22 14:11:35] {2219} INFO - iteration 33, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:35] {2392} INFO -  at 10.2s,\testimator xgboost's best error=0.1409,\tbest estimator lgbm's best error=0.1383\n",
      "[flaml.automl.logger: 07-22 14:11:35] {2219} INFO - iteration 34, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:11:35] {2392} INFO -  at 10.4s,\testimator lgbm's best error=0.1383,\tbest estimator lgbm's best error=0.1383\n",
      "[flaml.automl.logger: 07-22 14:11:35] {2219} INFO - iteration 35, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:11:36] {2392} INFO -  at 10.8s,\testimator rf's best error=0.1540,\tbest estimator lgbm's best error=0.1383\n",
      "[flaml.automl.logger: 07-22 14:11:36] {2219} INFO - iteration 36, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:36] {2392} INFO -  at 11.2s,\testimator xgboost's best error=0.1409,\tbest estimator lgbm's best error=0.1383\n",
      "[flaml.automl.logger: 07-22 14:11:36] {2219} INFO - iteration 37, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:11:37] {2392} INFO -  at 11.8s,\testimator rf's best error=0.1540,\tbest estimator lgbm's best error=0.1383\n",
      "[flaml.automl.logger: 07-22 14:11:37] {2219} INFO - iteration 38, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:37] {2392} INFO -  at 12.1s,\testimator xgboost's best error=0.1409,\tbest estimator lgbm's best error=0.1383\n",
      "[flaml.automl.logger: 07-22 14:11:37] {2219} INFO - iteration 39, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:11:37] {2392} INFO -  at 12.2s,\testimator lgbm's best error=0.1383,\tbest estimator lgbm's best error=0.1383\n",
      "[flaml.automl.logger: 07-22 14:11:37] {2219} INFO - iteration 40, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:37] {2392} INFO -  at 12.4s,\testimator xgboost's best error=0.1371,\tbest estimator xgboost's best error=0.1371\n",
      "[flaml.automl.logger: 07-22 14:11:37] {2219} INFO - iteration 41, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:37] {2392} INFO -  at 12.6s,\testimator xgboost's best error=0.1371,\tbest estimator xgboost's best error=0.1371\n",
      "[flaml.automl.logger: 07-22 14:11:37] {2219} INFO - iteration 42, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:11:38] {2392} INFO -  at 12.8s,\testimator lgbm's best error=0.1383,\tbest estimator xgboost's best error=0.1371\n",
      "[flaml.automl.logger: 07-22 14:11:38] {2219} INFO - iteration 43, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:38] {2392} INFO -  at 13.0s,\testimator xgboost's best error=0.1371,\tbest estimator xgboost's best error=0.1371\n",
      "[flaml.automl.logger: 07-22 14:11:38] {2219} INFO - iteration 44, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:38] {2392} INFO -  at 13.3s,\testimator xgboost's best error=0.1371,\tbest estimator xgboost's best error=0.1371\n",
      "[flaml.automl.logger: 07-22 14:11:38] {2219} INFO - iteration 45, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:38] {2392} INFO -  at 13.5s,\testimator xgboost's best error=0.1371,\tbest estimator xgboost's best error=0.1371\n",
      "[flaml.automl.logger: 07-22 14:11:38] {2219} INFO - iteration 46, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:11:38] {2392} INFO -  at 13.6s,\testimator lgbm's best error=0.1383,\tbest estimator xgboost's best error=0.1371\n",
      "[flaml.automl.logger: 07-22 14:11:38] {2219} INFO - iteration 47, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:39] {2392} INFO -  at 13.9s,\testimator xgboost's best error=0.1371,\tbest estimator xgboost's best error=0.1371\n",
      "[flaml.automl.logger: 07-22 14:11:39] {2219} INFO - iteration 48, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:11:39] {2392} INFO -  at 14.0s,\testimator lgbm's best error=0.1383,\tbest estimator xgboost's best error=0.1371\n",
      "[flaml.automl.logger: 07-22 14:11:39] {2219} INFO - iteration 49, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:39] {2392} INFO -  at 14.1s,\testimator xgboost's best error=0.1371,\tbest estimator xgboost's best error=0.1371\n",
      "[flaml.automl.logger: 07-22 14:11:39] {2219} INFO - iteration 50, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:39] {2392} INFO -  at 14.5s,\testimator xgboost's best error=0.1371,\tbest estimator xgboost's best error=0.1371\n",
      "[flaml.automl.logger: 07-22 14:11:39] {2219} INFO - iteration 51, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:11:39] {2392} INFO -  at 14.6s,\testimator lgbm's best error=0.1383,\tbest estimator xgboost's best error=0.1371\n",
      "[flaml.automl.logger: 07-22 14:11:39] {2219} INFO - iteration 52, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:11:40] {2392} INFO -  at 14.7s,\testimator lgbm's best error=0.1383,\tbest estimator xgboost's best error=0.1371\n",
      "[flaml.automl.logger: 07-22 14:11:40] {2219} INFO - iteration 53, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:11:40] {2392} INFO -  at 14.9s,\testimator lgbm's best error=0.1383,\tbest estimator xgboost's best error=0.1371\n",
      "[flaml.automl.logger: 07-22 14:11:40] {2219} INFO - iteration 54, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:11:40] {2392} INFO -  at 15.0s,\testimator lgbm's best error=0.1383,\tbest estimator xgboost's best error=0.1371\n",
      "[flaml.automl.logger: 07-22 14:11:40] {2219} INFO - iteration 55, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:40] {2392} INFO -  at 15.3s,\testimator xgboost's best error=0.1342,\tbest estimator xgboost's best error=0.1342\n",
      "[flaml.automl.logger: 07-22 14:11:40] {2219} INFO - iteration 56, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:11:40] {2392} INFO -  at 15.7s,\testimator rf's best error=0.1535,\tbest estimator xgboost's best error=0.1342\n",
      "[flaml.automl.logger: 07-22 14:11:40] {2219} INFO - iteration 57, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:41] {2392} INFO -  at 15.9s,\testimator xgboost's best error=0.1342,\tbest estimator xgboost's best error=0.1342\n",
      "[flaml.automl.logger: 07-22 14:11:41] {2219} INFO - iteration 58, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:41] {2392} INFO -  at 16.3s,\testimator xgboost's best error=0.1342,\tbest estimator xgboost's best error=0.1342\n",
      "[flaml.automl.logger: 07-22 14:11:41] {2219} INFO - iteration 59, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:11:41] {2392} INFO -  at 16.4s,\testimator lgbm's best error=0.1383,\tbest estimator xgboost's best error=0.1342\n",
      "[flaml.automl.logger: 07-22 14:11:41] {2219} INFO - iteration 60, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:41] {2392} INFO -  at 16.6s,\testimator xgboost's best error=0.1342,\tbest estimator xgboost's best error=0.1342\n",
      "[flaml.automl.logger: 07-22 14:11:41] {2219} INFO - iteration 61, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:11:42] {2392} INFO -  at 16.8s,\testimator lgbm's best error=0.1335,\tbest estimator lgbm's best error=0.1335\n",
      "[flaml.automl.logger: 07-22 14:11:42] {2219} INFO - iteration 62, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:42] {2392} INFO -  at 17.0s,\testimator xgboost's best error=0.1342,\tbest estimator lgbm's best error=0.1335\n",
      "[flaml.automl.logger: 07-22 14:11:42] {2219} INFO - iteration 63, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:42] {2392} INFO -  at 17.4s,\testimator xgboost's best error=0.1335,\tbest estimator lgbm's best error=0.1335\n",
      "[flaml.automl.logger: 07-22 14:11:42] {2219} INFO - iteration 64, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:11:42] {2392} INFO -  at 17.5s,\testimator lgbm's best error=0.1335,\tbest estimator lgbm's best error=0.1335\n",
      "[flaml.automl.logger: 07-22 14:11:42] {2219} INFO - iteration 65, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:43] {2392} INFO -  at 17.9s,\testimator xgboost's best error=0.1335,\tbest estimator lgbm's best error=0.1335\n",
      "[flaml.automl.logger: 07-22 14:11:43] {2219} INFO - iteration 66, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:43] {2392} INFO -  at 18.2s,\testimator xgboost's best error=0.1335,\tbest estimator lgbm's best error=0.1335\n",
      "[flaml.automl.logger: 07-22 14:11:43] {2219} INFO - iteration 67, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:43] {2392} INFO -  at 18.4s,\testimator xgboost's best error=0.1335,\tbest estimator lgbm's best error=0.1335\n",
      "[flaml.automl.logger: 07-22 14:11:43] {2219} INFO - iteration 68, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:11:43] {2392} INFO -  at 18.6s,\testimator lgbm's best error=0.1335,\tbest estimator lgbm's best error=0.1335\n",
      "[flaml.automl.logger: 07-22 14:11:43] {2219} INFO - iteration 69, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:44] {2392} INFO -  at 19.4s,\testimator xgboost's best error=0.1335,\tbest estimator lgbm's best error=0.1335\n",
      "[flaml.automl.logger: 07-22 14:11:44] {2219} INFO - iteration 70, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:45] {2392} INFO -  at 19.8s,\testimator xgboost's best error=0.1335,\tbest estimator lgbm's best error=0.1335\n",
      "[flaml.automl.logger: 07-22 14:11:45] {2219} INFO - iteration 71, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:45] {2392} INFO -  at 20.2s,\testimator xgboost's best error=0.1335,\tbest estimator lgbm's best error=0.1335\n",
      "[flaml.automl.logger: 07-22 14:11:45] {2219} INFO - iteration 72, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:46] {2392} INFO -  at 20.7s,\testimator xgboost's best error=0.1335,\tbest estimator lgbm's best error=0.1335\n",
      "[flaml.automl.logger: 07-22 14:11:46] {2219} INFO - iteration 73, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:46] {2392} INFO -  at 21.0s,\testimator xgboost's best error=0.1335,\tbest estimator lgbm's best error=0.1335\n",
      "[flaml.automl.logger: 07-22 14:11:46] {2219} INFO - iteration 74, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:46] {2392} INFO -  at 21.3s,\testimator xgboost's best error=0.1335,\tbest estimator lgbm's best error=0.1335\n",
      "[flaml.automl.logger: 07-22 14:11:46] {2219} INFO - iteration 75, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:11:46] {2392} INFO -  at 21.4s,\testimator lgbm's best error=0.1335,\tbest estimator lgbm's best error=0.1335\n",
      "[flaml.automl.logger: 07-22 14:11:46] {2219} INFO - iteration 76, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:11:47] {2392} INFO -  at 21.7s,\testimator lgbm's best error=0.1335,\tbest estimator lgbm's best error=0.1335\n",
      "[flaml.automl.logger: 07-22 14:11:47] {2219} INFO - iteration 77, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:47] {2392} INFO -  at 22.0s,\testimator xgboost's best error=0.1335,\tbest estimator lgbm's best error=0.1335\n",
      "[flaml.automl.logger: 07-22 14:11:47] {2219} INFO - iteration 78, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:11:47] {2392} INFO -  at 22.1s,\testimator lgbm's best error=0.1335,\tbest estimator lgbm's best error=0.1335\n",
      "[flaml.automl.logger: 07-22 14:11:47] {2219} INFO - iteration 79, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:11:47] {2392} INFO -  at 22.3s,\testimator lgbm's best error=0.1335,\tbest estimator lgbm's best error=0.1335\n",
      "[flaml.automl.logger: 07-22 14:11:47] {2219} INFO - iteration 80, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:48] {2392} INFO -  at 22.8s,\testimator xgboost's best error=0.1335,\tbest estimator lgbm's best error=0.1335\n",
      "[flaml.automl.logger: 07-22 14:11:48] {2219} INFO - iteration 81, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:11:48] {2392} INFO -  at 22.9s,\testimator lgbm's best error=0.1335,\tbest estimator lgbm's best error=0.1335\n",
      "[flaml.automl.logger: 07-22 14:11:48] {2219} INFO - iteration 82, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:48] {2392} INFO -  at 23.2s,\testimator xgboost's best error=0.1335,\tbest estimator lgbm's best error=0.1335\n",
      "[flaml.automl.logger: 07-22 14:11:48] {2219} INFO - iteration 83, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:48] {2392} INFO -  at 23.6s,\testimator xgboost's best error=0.1335,\tbest estimator lgbm's best error=0.1335\n",
      "[flaml.automl.logger: 07-22 14:11:48] {2219} INFO - iteration 84, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:49] {2392} INFO -  at 23.9s,\testimator xgboost's best error=0.1335,\tbest estimator lgbm's best error=0.1335\n",
      "[flaml.automl.logger: 07-22 14:11:49] {2219} INFO - iteration 85, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:11:49] {2392} INFO -  at 24.2s,\testimator lgbm's best error=0.1335,\tbest estimator lgbm's best error=0.1335\n",
      "[flaml.automl.logger: 07-22 14:11:49] {2219} INFO - iteration 86, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:50] {2392} INFO -  at 24.9s,\testimator xgboost's best error=0.1317,\tbest estimator xgboost's best error=0.1317\n",
      "[flaml.automl.logger: 07-22 14:11:50] {2219} INFO - iteration 87, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:11:50] {2392} INFO -  at 25.0s,\testimator lgbm's best error=0.1335,\tbest estimator xgboost's best error=0.1317\n",
      "[flaml.automl.logger: 07-22 14:11:50] {2219} INFO - iteration 88, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:11:50] {2392} INFO -  at 25.1s,\testimator lgbm's best error=0.1335,\tbest estimator xgboost's best error=0.1317\n",
      "[flaml.automl.logger: 07-22 14:11:50] {2219} INFO - iteration 89, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:50] {2392} INFO -  at 25.4s,\testimator xgboost's best error=0.1317,\tbest estimator xgboost's best error=0.1317\n",
      "[flaml.automl.logger: 07-22 14:11:50] {2219} INFO - iteration 90, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:11:50] {2392} INFO -  at 25.6s,\testimator lgbm's best error=0.1335,\tbest estimator xgboost's best error=0.1317\n",
      "[flaml.automl.logger: 07-22 14:11:50] {2219} INFO - iteration 91, current learner extra_tree\n",
      "[flaml.automl.logger: 07-22 14:11:51] {2392} INFO -  at 26.0s,\testimator extra_tree's best error=0.1679,\tbest estimator xgboost's best error=0.1317\n",
      "[flaml.automl.logger: 07-22 14:11:51] {2219} INFO - iteration 92, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:52] {2392} INFO -  at 27.6s,\testimator xgboost's best error=0.1317,\tbest estimator xgboost's best error=0.1317\n",
      "[flaml.automl.logger: 07-22 14:11:52] {2219} INFO - iteration 93, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:11:53] {2392} INFO -  at 28.0s,\testimator rf's best error=0.1535,\tbest estimator xgboost's best error=0.1317\n",
      "[flaml.automl.logger: 07-22 14:11:53] {2219} INFO - iteration 94, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:11:53] {2392} INFO -  at 28.2s,\testimator lgbm's best error=0.1335,\tbest estimator xgboost's best error=0.1317\n",
      "[flaml.automl.logger: 07-22 14:11:53] {2219} INFO - iteration 95, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:53] {2392} INFO -  at 28.6s,\testimator xgboost's best error=0.1317,\tbest estimator xgboost's best error=0.1317\n",
      "[flaml.automl.logger: 07-22 14:11:53] {2219} INFO - iteration 96, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:11:54] {2392} INFO -  at 28.9s,\testimator lgbm's best error=0.1335,\tbest estimator xgboost's best error=0.1317\n",
      "[flaml.automl.logger: 07-22 14:11:54] {2219} INFO - iteration 97, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:11:54] {2392} INFO -  at 29.1s,\testimator lgbm's best error=0.1335,\tbest estimator xgboost's best error=0.1317\n",
      "[flaml.automl.logger: 07-22 14:11:54] {2219} INFO - iteration 98, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:11:54] {2392} INFO -  at 29.2s,\testimator lgbm's best error=0.1335,\tbest estimator xgboost's best error=0.1317\n",
      "[flaml.automl.logger: 07-22 14:11:54] {2219} INFO - iteration 99, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:11:54] {2392} INFO -  at 29.5s,\testimator lgbm's best error=0.1335,\tbest estimator xgboost's best error=0.1317\n",
      "[flaml.automl.logger: 07-22 14:11:54] {2219} INFO - iteration 100, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:11:55] {2392} INFO -  at 30.5s,\testimator xgboost's best error=0.1317,\tbest estimator xgboost's best error=0.1317\n",
      "[flaml.automl.logger: 07-22 14:11:55] {2219} INFO - iteration 101, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:11:56] {2392} INFO -  at 31.1s,\testimator rf's best error=0.1494,\tbest estimator xgboost's best error=0.1317\n",
      "[flaml.automl.logger: 07-22 14:11:56] {2219} INFO - iteration 102, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:11:56] {2392} INFO -  at 31.2s,\testimator lgbm's best error=0.1335,\tbest estimator xgboost's best error=0.1317\n",
      "[flaml.automl.logger: 07-22 14:11:56] {2219} INFO - iteration 103, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:11:57] {2392} INFO -  at 32.3s,\testimator rf's best error=0.1494,\tbest estimator xgboost's best error=0.1317\n",
      "[flaml.automl.logger: 07-22 14:11:57] {2219} INFO - iteration 104, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:11:57] {2392} INFO -  at 32.6s,\testimator lgbm's best error=0.1335,\tbest estimator xgboost's best error=0.1317\n",
      "[flaml.automl.logger: 07-22 14:11:57] {2219} INFO - iteration 105, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:11:59] {2392} INFO -  at 34.3s,\testimator catboost's best error=0.1326,\tbest estimator xgboost's best error=0.1317\n",
      "[flaml.automl.logger: 07-22 14:11:59] {2219} INFO - iteration 106, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:12:02] {2392} INFO -  at 36.9s,\testimator catboost's best error=0.1326,\tbest estimator xgboost's best error=0.1317\n",
      "[flaml.automl.logger: 07-22 14:12:02] {2219} INFO - iteration 107, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:12:02] {2392} INFO -  at 37.5s,\testimator xgboost's best error=0.1317,\tbest estimator xgboost's best error=0.1317\n",
      "[flaml.automl.logger: 07-22 14:12:02] {2219} INFO - iteration 108, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:12:04] {2392} INFO -  at 39.2s,\testimator catboost's best error=0.1326,\tbest estimator xgboost's best error=0.1317\n",
      "[flaml.automl.logger: 07-22 14:12:04] {2219} INFO - iteration 109, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:12:05] {2392} INFO -  at 39.9s,\testimator xgboost's best error=0.1317,\tbest estimator xgboost's best error=0.1317\n",
      "[flaml.automl.logger: 07-22 14:12:05] {2219} INFO - iteration 110, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:12:07] {2392} INFO -  at 42.3s,\testimator catboost's best error=0.1326,\tbest estimator xgboost's best error=0.1317\n",
      "[flaml.automl.logger: 07-22 14:12:07] {2219} INFO - iteration 111, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:12:07] {2392} INFO -  at 42.5s,\testimator lgbm's best error=0.1335,\tbest estimator xgboost's best error=0.1317\n",
      "[flaml.automl.logger: 07-22 14:12:07] {2219} INFO - iteration 112, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:12:08] {2392} INFO -  at 43.4s,\testimator xgboost's best error=0.1317,\tbest estimator xgboost's best error=0.1317\n",
      "[flaml.automl.logger: 07-22 14:12:08] {2219} INFO - iteration 113, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:12:10] {2392} INFO -  at 45.0s,\testimator catboost's best error=0.1326,\tbest estimator xgboost's best error=0.1317\n",
      "[flaml.automl.logger: 07-22 14:12:10] {2219} INFO - iteration 114, current learner extra_tree\n",
      "[flaml.automl.logger: 07-22 14:12:11] {2392} INFO -  at 46.0s,\testimator extra_tree's best error=0.1679,\tbest estimator xgboost's best error=0.1317\n",
      "[flaml.automl.logger: 07-22 14:12:11] {2219} INFO - iteration 115, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:12:11] {2392} INFO -  at 46.4s,\testimator lgbm's best error=0.1335,\tbest estimator xgboost's best error=0.1317\n",
      "[flaml.automl.logger: 07-22 14:12:11] {2219} INFO - iteration 116, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:12:11] {2392} INFO -  at 46.5s,\testimator lgbm's best error=0.1335,\tbest estimator xgboost's best error=0.1317\n",
      "[flaml.automl.logger: 07-22 14:12:11] {2219} INFO - iteration 117, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:12:12] {2392} INFO -  at 47.0s,\testimator xgboost's best error=0.1317,\tbest estimator xgboost's best error=0.1317\n",
      "[flaml.automl.logger: 07-22 14:12:12] {2219} INFO - iteration 118, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:12:12] {2392} INFO -  at 47.6s,\testimator xgboost's best error=0.1317,\tbest estimator xgboost's best error=0.1317\n",
      "[flaml.automl.logger: 07-22 14:12:12] {2219} INFO - iteration 119, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:12:13] {2392} INFO -  at 47.9s,\testimator lgbm's best error=0.1335,\tbest estimator xgboost's best error=0.1317\n",
      "[flaml.automl.logger: 07-22 14:12:13] {2219} INFO - iteration 120, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:12:14] {2392} INFO -  at 48.8s,\testimator xgboost's best error=0.1317,\tbest estimator xgboost's best error=0.1317\n",
      "[flaml.automl.logger: 07-22 14:12:14] {2219} INFO - iteration 121, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:12:14] {2392} INFO -  at 49.3s,\testimator xgboost's best error=0.1317,\tbest estimator xgboost's best error=0.1317\n",
      "[flaml.automl.logger: 07-22 14:12:14] {2219} INFO - iteration 122, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:12:15] {2392} INFO -  at 49.9s,\testimator xgboost's best error=0.1317,\tbest estimator xgboost's best error=0.1317\n",
      "[flaml.automl.logger: 07-22 14:12:15] {2219} INFO - iteration 123, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:12:16] {2392} INFO -  at 51.5s,\testimator catboost's best error=0.1326,\tbest estimator xgboost's best error=0.1317\n",
      "[flaml.automl.logger: 07-22 14:12:16] {2219} INFO - iteration 124, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:12:16] {2392} INFO -  at 51.7s,\testimator lgbm's best error=0.1335,\tbest estimator xgboost's best error=0.1317\n",
      "[flaml.automl.logger: 07-22 14:12:16] {2219} INFO - iteration 125, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:12:17] {2392} INFO -  at 51.8s,\testimator lgbm's best error=0.1335,\tbest estimator xgboost's best error=0.1317\n",
      "[flaml.automl.logger: 07-22 14:12:17] {2219} INFO - iteration 126, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:12:17] {2392} INFO -  at 52.0s,\testimator lgbm's best error=0.1335,\tbest estimator xgboost's best error=0.1317\n",
      "[flaml.automl.logger: 07-22 14:12:17] {2219} INFO - iteration 127, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:12:17] {2392} INFO -  at 52.1s,\testimator lgbm's best error=0.1335,\tbest estimator xgboost's best error=0.1317\n",
      "[flaml.automl.logger: 07-22 14:12:17] {2219} INFO - iteration 128, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:12:17] {2392} INFO -  at 52.4s,\testimator lgbm's best error=0.1335,\tbest estimator xgboost's best error=0.1317\n",
      "[flaml.automl.logger: 07-22 14:12:17] {2219} INFO - iteration 129, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:12:18] {2392} INFO -  at 53.3s,\testimator xgboost's best error=0.1317,\tbest estimator xgboost's best error=0.1317\n",
      "[flaml.automl.logger: 07-22 14:12:18] {2219} INFO - iteration 130, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:12:20] {2392} INFO -  at 54.9s,\testimator catboost's best error=0.1326,\tbest estimator xgboost's best error=0.1317\n",
      "[flaml.automl.logger: 07-22 14:12:20] {2219} INFO - iteration 131, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:12:22] {2392} INFO -  at 56.9s,\testimator catboost's best error=0.1326,\tbest estimator xgboost's best error=0.1317\n",
      "[flaml.automl.logger: 07-22 14:12:22] {2219} INFO - iteration 132, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:12:22] {2392} INFO -  at 57.6s,\testimator xgboost's best error=0.1317,\tbest estimator xgboost's best error=0.1317\n",
      "[flaml.automl.logger: 07-22 14:12:22] {2219} INFO - iteration 133, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:12:23] {2392} INFO -  at 57.7s,\testimator lgbm's best error=0.1335,\tbest estimator xgboost's best error=0.1317\n",
      "[flaml.automl.logger: 07-22 14:12:23] {2219} INFO - iteration 134, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:12:23] {2392} INFO -  at 58.0s,\testimator lgbm's best error=0.1335,\tbest estimator xgboost's best error=0.1317\n",
      "[flaml.automl.logger: 07-22 14:12:23] {2219} INFO - iteration 135, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:12:25] {2392} INFO -  at 59.9s,\testimator catboost's best error=0.1308,\tbest estimator catboost's best error=0.1308\n",
      "[flaml.automl.logger: 07-22 14:12:25] {2219} INFO - iteration 136, current learner extra_tree\n",
      "[flaml.automl.logger: 07-22 14:12:25] {2392} INFO -  at 60.6s,\testimator extra_tree's best error=0.1671,\tbest estimator catboost's best error=0.1308\n",
      "[flaml.automl.logger: 07-22 14:12:25] {2219} INFO - iteration 137, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:12:28] {2392} INFO -  at 62.7s,\testimator catboost's best error=0.1279,\tbest estimator catboost's best error=0.1279\n",
      "[flaml.automl.logger: 07-22 14:12:28] {2219} INFO - iteration 138, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:12:28] {2392} INFO -  at 63.0s,\testimator lgbm's best error=0.1335,\tbest estimator catboost's best error=0.1279\n",
      "[flaml.automl.logger: 07-22 14:12:28] {2219} INFO - iteration 139, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:12:30] {2392} INFO -  at 64.9s,\testimator catboost's best error=0.1279,\tbest estimator catboost's best error=0.1279\n",
      "[flaml.automl.logger: 07-22 14:12:30] {2219} INFO - iteration 140, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:12:32] {2392} INFO -  at 67.0s,\testimator catboost's best error=0.1279,\tbest estimator catboost's best error=0.1279\n",
      "[flaml.automl.logger: 07-22 14:12:32] {2219} INFO - iteration 141, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:12:34] {2392} INFO -  at 69.4s,\testimator catboost's best error=0.1279,\tbest estimator catboost's best error=0.1279\n",
      "[flaml.automl.logger: 07-22 14:12:34] {2219} INFO - iteration 142, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:12:36] {2392} INFO -  at 71.6s,\testimator catboost's best error=0.1279,\tbest estimator catboost's best error=0.1279\n",
      "[flaml.automl.logger: 07-22 14:12:36] {2219} INFO - iteration 143, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:12:39] {2392} INFO -  at 73.8s,\testimator catboost's best error=0.1279,\tbest estimator catboost's best error=0.1279\n",
      "[flaml.automl.logger: 07-22 14:12:39] {2219} INFO - iteration 144, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:12:41] {2392} INFO -  at 75.8s,\testimator catboost's best error=0.1263,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:12:41] {2219} INFO - iteration 145, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:12:43] {2392} INFO -  at 78.1s,\testimator catboost's best error=0.1263,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:12:43] {2219} INFO - iteration 146, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:12:43] {2392} INFO -  at 78.3s,\testimator lgbm's best error=0.1335,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:12:43] {2219} INFO - iteration 147, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:12:43] {2392} INFO -  at 78.4s,\testimator lgbm's best error=0.1335,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:12:43] {2219} INFO - iteration 148, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:12:43] {2392} INFO -  at 78.6s,\testimator lgbm's best error=0.1335,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:12:43] {2219} INFO - iteration 149, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:12:44] {2392} INFO -  at 78.8s,\testimator lgbm's best error=0.1335,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:12:44] {2219} INFO - iteration 150, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:12:44] {2392} INFO -  at 79.0s,\testimator lgbm's best error=0.1335,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:12:44] {2219} INFO - iteration 151, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:12:44] {2392} INFO -  at 79.5s,\testimator rf's best error=0.1414,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:12:44] {2219} INFO - iteration 152, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:12:46] {2392} INFO -  at 81.5s,\testimator catboost's best error=0.1263,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:12:46] {2219} INFO - iteration 153, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:12:47] {2392} INFO -  at 82.1s,\testimator rf's best error=0.1414,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:12:47] {2219} INFO - iteration 154, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:12:47] {2392} INFO -  at 82.3s,\testimator lgbm's best error=0.1335,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:12:47] {2219} INFO - iteration 155, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:12:47] {2392} INFO -  at 82.5s,\testimator lgbm's best error=0.1335,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:12:47] {2219} INFO - iteration 156, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:12:49] {2392} INFO -  at 83.7s,\testimator xgboost's best error=0.1317,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:12:49] {2219} INFO - iteration 157, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:12:49] {2392} INFO -  at 84.1s,\testimator rf's best error=0.1414,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:12:49] {2219} INFO - iteration 158, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:12:50] {2392} INFO -  at 84.8s,\testimator rf's best error=0.1414,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:12:50] {2219} INFO - iteration 159, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:12:50] {2392} INFO -  at 85.2s,\testimator rf's best error=0.1414,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:12:50] {2219} INFO - iteration 160, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:12:53] {2392} INFO -  at 87.8s,\testimator catboost's best error=0.1263,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:12:53] {2219} INFO - iteration 161, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:12:53] {2392} INFO -  at 88.7s,\testimator rf's best error=0.1414,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:12:53] {2219} INFO - iteration 162, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:12:56] {2392} INFO -  at 90.8s,\testimator catboost's best error=0.1263,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:12:56] {2219} INFO - iteration 163, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:12:56] {2392} INFO -  at 91.5s,\testimator xgboost's best error=0.1317,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:12:56] {2219} INFO - iteration 164, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:12:58] {2392} INFO -  at 93.0s,\testimator catboost's best error=0.1263,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:12:58] {2219} INFO - iteration 165, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:12:58] {2392} INFO -  at 93.6s,\testimator rf's best error=0.1414,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:12:58] {2219} INFO - iteration 166, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:13:00] {2392} INFO -  at 95.6s,\testimator catboost's best error=0.1263,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:00] {2219} INFO - iteration 167, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:13:03] {2392} INFO -  at 97.7s,\testimator catboost's best error=0.1263,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:03] {2219} INFO - iteration 168, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:13:06] {2392} INFO -  at 100.9s,\testimator catboost's best error=0.1263,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:06] {2219} INFO - iteration 169, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:13:06] {2392} INFO -  at 101.3s,\testimator xgb_limitdepth's best error=0.1406,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:06] {2219} INFO - iteration 170, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:13:06] {2392} INFO -  at 101.5s,\testimator xgb_limitdepth's best error=0.1406,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:06] {2219} INFO - iteration 171, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:13:07] {2392} INFO -  at 101.9s,\testimator rf's best error=0.1414,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:07] {2219} INFO - iteration 172, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:13:07] {2392} INFO -  at 102.2s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:07] {2219} INFO - iteration 173, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:13:07] {2392} INFO -  at 102.4s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:07] {2219} INFO - iteration 174, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:13:07] {2392} INFO -  at 102.7s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:07] {2219} INFO - iteration 175, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:13:08] {2392} INFO -  at 102.9s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:08] {2219} INFO - iteration 176, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:13:08] {2392} INFO -  at 103.5s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:08] {2219} INFO - iteration 177, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:13:09] {2392} INFO -  at 103.8s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:09] {2219} INFO - iteration 178, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:13:09] {2392} INFO -  at 104.0s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:09] {2219} INFO - iteration 179, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:13:09] {2392} INFO -  at 104.2s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:09] {2219} INFO - iteration 180, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:13:09] {2392} INFO -  at 104.5s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:09] {2219} INFO - iteration 181, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:13:10] {2392} INFO -  at 104.7s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:10] {2219} INFO - iteration 182, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:13:10] {2392} INFO -  at 105.0s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:10] {2219} INFO - iteration 183, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:13:11] {2392} INFO -  at 106.6s,\testimator catboost's best error=0.1263,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:11] {2219} INFO - iteration 184, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:13:12] {2392} INFO -  at 106.8s,\testimator lgbm's best error=0.1335,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:12] {2219} INFO - iteration 185, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:13:14] {2392} INFO -  at 109.6s,\testimator catboost's best error=0.1263,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:14] {2219} INFO - iteration 186, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:13:15] {2392} INFO -  at 109.8s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:15] {2219} INFO - iteration 187, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:13:15] {2392} INFO -  at 110.2s,\testimator rf's best error=0.1414,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:15] {2219} INFO - iteration 188, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:13:16] {2392} INFO -  at 110.7s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:16] {2219} INFO - iteration 189, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:13:16] {2392} INFO -  at 110.8s,\testimator lgbm's best error=0.1335,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:16] {2219} INFO - iteration 190, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:13:17] {2392} INFO -  at 112.4s,\testimator catboost's best error=0.1263,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:17] {2219} INFO - iteration 191, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:13:18] {2392} INFO -  at 112.8s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:18] {2219} INFO - iteration 192, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:13:18] {2392} INFO -  at 113.2s,\testimator rf's best error=0.1414,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:18] {2219} INFO - iteration 193, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:13:18] {2392} INFO -  at 113.5s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:18] {2219} INFO - iteration 194, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:13:19] {2392} INFO -  at 114.0s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:19] {2219} INFO - iteration 195, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:13:19] {2392} INFO -  at 114.2s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:19] {2219} INFO - iteration 196, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:13:20] {2392} INFO -  at 115.1s,\testimator rf's best error=0.1322,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:20] {2219} INFO - iteration 197, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:13:20] {2392} INFO -  at 115.4s,\testimator lgbm's best error=0.1335,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:20] {2219} INFO - iteration 198, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:13:20] {2392} INFO -  at 115.6s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:20] {2219} INFO - iteration 199, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:13:21] {2392} INFO -  at 115.9s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:21] {2219} INFO - iteration 200, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:13:21] {2392} INFO -  at 116.0s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:21] {2219} INFO - iteration 201, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:13:21] {2392} INFO -  at 116.3s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:21] {2219} INFO - iteration 202, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:13:21] {2392} INFO -  at 116.5s,\testimator lgbm's best error=0.1335,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:21] {2219} INFO - iteration 203, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:13:22] {2392} INFO -  at 117.5s,\testimator rf's best error=0.1322,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:22] {2219} INFO - iteration 204, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:13:23] {2392} INFO -  at 118.4s,\testimator xgboost's best error=0.1317,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:23] {2219} INFO - iteration 205, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:13:23] {2392} INFO -  at 118.7s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:23] {2219} INFO - iteration 206, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:13:24] {2392} INFO -  at 118.9s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:24] {2219} INFO - iteration 207, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:13:26] {2392} INFO -  at 121.7s,\testimator catboost's best error=0.1263,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:26] {2219} INFO - iteration 208, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:13:27] {2392} INFO -  at 121.9s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:27] {2219} INFO - iteration 209, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:13:27] {2392} INFO -  at 122.4s,\testimator xgboost's best error=0.1317,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:27] {2219} INFO - iteration 210, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:13:28] {2392} INFO -  at 123.3s,\testimator rf's best error=0.1322,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:28] {2219} INFO - iteration 211, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:13:30] {2392} INFO -  at 125.4s,\testimator catboost's best error=0.1263,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:30] {2219} INFO - iteration 212, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:13:31] {2392} INFO -  at 126.6s,\testimator xgboost's best error=0.1317,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:31] {2219} INFO - iteration 213, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:13:34] {2392} INFO -  at 128.8s,\testimator catboost's best error=0.1263,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:34] {2219} INFO - iteration 214, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:13:34] {2392} INFO -  at 129.4s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:34] {2219} INFO - iteration 215, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:13:34] {2392} INFO -  at 129.6s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:34] {2219} INFO - iteration 216, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:13:35] {2392} INFO -  at 130.1s,\testimator rf's best error=0.1322,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:35] {2219} INFO - iteration 217, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:13:35] {2392} INFO -  at 130.4s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:35] {2219} INFO - iteration 218, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:13:36] {2392} INFO -  at 131.5s,\testimator rf's best error=0.1322,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:36] {2219} INFO - iteration 219, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:13:37] {2392} INFO -  at 131.8s,\testimator lgbm's best error=0.1335,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:37] {2219} INFO - iteration 220, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:13:37] {2392} INFO -  at 132.2s,\testimator rf's best error=0.1322,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:37] {2219} INFO - iteration 221, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:13:40] {2392} INFO -  at 135.3s,\testimator catboost's best error=0.1263,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:40] {2219} INFO - iteration 222, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:13:40] {2392} INFO -  at 135.4s,\testimator lgbm's best error=0.1335,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:40] {2219} INFO - iteration 223, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:13:41] {2392} INFO -  at 135.7s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:41] {2219} INFO - iteration 224, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:13:41] {2392} INFO -  at 135.9s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:41] {2219} INFO - iteration 225, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:13:41] {2392} INFO -  at 136.1s,\testimator lgbm's best error=0.1335,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:41] {2219} INFO - iteration 226, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:13:42] {2392} INFO -  at 136.7s,\testimator rf's best error=0.1322,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:42] {2219} INFO - iteration 227, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:13:42] {2392} INFO -  at 137.7s,\testimator rf's best error=0.1322,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:42] {2219} INFO - iteration 228, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:13:43] {2392} INFO -  at 137.9s,\testimator lgbm's best error=0.1335,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:43] {2219} INFO - iteration 229, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:13:43] {2392} INFO -  at 138.1s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:43] {2219} INFO - iteration 230, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:13:44] {2392} INFO -  at 138.9s,\testimator rf's best error=0.1322,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:44] {2219} INFO - iteration 231, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:13:44] {2392} INFO -  at 139.1s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:44] {2219} INFO - iteration 232, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:13:46] {2392} INFO -  at 141.3s,\testimator catboost's best error=0.1263,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:46] {2219} INFO - iteration 233, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:13:46] {2392} INFO -  at 141.7s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:46] {2219} INFO - iteration 234, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:13:47] {2392} INFO -  at 141.9s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:47] {2219} INFO - iteration 235, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:13:47] {2392} INFO -  at 142.2s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:47] {2219} INFO - iteration 236, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:13:48] {2392} INFO -  at 143.2s,\testimator rf's best error=0.1322,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:48] {2219} INFO - iteration 237, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:13:50] {2392} INFO -  at 145.5s,\testimator catboost's best error=0.1263,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:50] {2219} INFO - iteration 238, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:13:51] {2392} INFO -  at 145.7s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:51] {2219} INFO - iteration 239, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:13:51] {2392} INFO -  at 146.2s,\testimator rf's best error=0.1322,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:51] {2219} INFO - iteration 240, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:13:53] {2392} INFO -  at 148.3s,\testimator catboost's best error=0.1263,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:53] {2219} INFO - iteration 241, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:13:55] {2392} INFO -  at 150.2s,\testimator xgboost's best error=0.1317,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:55] {2219} INFO - iteration 242, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:13:55] {2392} INFO -  at 150.4s,\testimator lgbm's best error=0.1335,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:55] {2219} INFO - iteration 243, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:13:55] {2392} INFO -  at 150.7s,\testimator xgboost's best error=0.1317,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:56] {2219} INFO - iteration 244, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:13:56] {2392} INFO -  at 151.7s,\testimator rf's best error=0.1322,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:56] {2219} INFO - iteration 245, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:13:57] {2392} INFO -  at 152.1s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:57] {2219} INFO - iteration 246, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:13:58] {2392} INFO -  at 153.0s,\testimator rf's best error=0.1322,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:58] {2219} INFO - iteration 247, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:13:58] {2392} INFO -  at 153.3s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:13:58] {2219} INFO - iteration 248, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:14:00] {2392} INFO -  at 155.6s,\testimator catboost's best error=0.1263,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:14:00] {2219} INFO - iteration 249, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:14:01] {2392} INFO -  at 156.2s,\testimator rf's best error=0.1322,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:14:01] {2219} INFO - iteration 250, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:14:01] {2392} INFO -  at 156.5s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:14:01] {2219} INFO - iteration 251, current learner xgboost\n",
      "[flaml.automl.logger: 07-22 14:14:02] {2392} INFO -  at 157.2s,\testimator xgboost's best error=0.1317,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:14:02] {2219} INFO - iteration 252, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:14:02] {2392} INFO -  at 157.4s,\testimator lgbm's best error=0.1335,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:14:02] {2219} INFO - iteration 253, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:14:03] {2392} INFO -  at 158.3s,\testimator rf's best error=0.1303,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:14:03] {2219} INFO - iteration 254, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:14:03] {2392} INFO -  at 158.6s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:14:03] {2219} INFO - iteration 255, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:14:04] {2392} INFO -  at 158.9s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:14:04] {2219} INFO - iteration 256, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:14:04] {2392} INFO -  at 159.1s,\testimator lgbm's best error=0.1335,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:14:04] {2219} INFO - iteration 257, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:14:04] {2392} INFO -  at 159.3s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:14:04] {2219} INFO - iteration 258, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:14:06] {2392} INFO -  at 161.4s,\testimator catboost's best error=0.1263,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:14:06] {2219} INFO - iteration 259, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:14:07] {2392} INFO -  at 161.7s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:14:07] {2219} INFO - iteration 260, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:14:07] {2392} INFO -  at 162.0s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:14:07] {2219} INFO - iteration 261, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:14:07] {2392} INFO -  at 162.2s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:14:07] {2219} INFO - iteration 262, current learner extra_tree\n",
      "[flaml.automl.logger: 07-22 14:14:08] {2392} INFO -  at 162.7s,\testimator extra_tree's best error=0.1620,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:14:08] {2219} INFO - iteration 263, current learner extra_tree\n",
      "[flaml.automl.logger: 07-22 14:14:08] {2392} INFO -  at 163.5s,\testimator extra_tree's best error=0.1593,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:14:08] {2219} INFO - iteration 264, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:14:10] {2392} INFO -  at 165.6s,\testimator catboost's best error=0.1263,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:14:10] {2219} INFO - iteration 265, current learner extra_tree\n",
      "[flaml.automl.logger: 07-22 14:14:11] {2392} INFO -  at 166.5s,\testimator extra_tree's best error=0.1593,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:14:11] {2219} INFO - iteration 266, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:14:12] {2392} INFO -  at 166.8s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:14:12] {2219} INFO - iteration 267, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:14:12] {2392} INFO -  at 167.0s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:14:12] {2219} INFO - iteration 268, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:14:12] {2392} INFO -  at 167.2s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:14:12] {2219} INFO - iteration 269, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:14:12] {2392} INFO -  at 167.4s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:14:12] {2219} INFO - iteration 270, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:14:13] {2392} INFO -  at 167.7s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:14:13] {2219} INFO - iteration 271, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:14:14] {2392} INFO -  at 168.9s,\testimator rf's best error=0.1303,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:14:14] {2219} INFO - iteration 272, current learner extra_tree\n",
      "[flaml.automl.logger: 07-22 14:14:14] {2392} INFO -  at 169.3s,\testimator extra_tree's best error=0.1593,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:14:14] {2219} INFO - iteration 273, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:14:16] {2392} INFO -  at 171.3s,\testimator catboost's best error=0.1263,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:14:16] {2219} INFO - iteration 274, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:14:19] {2392} INFO -  at 173.7s,\testimator catboost's best error=0.1263,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:14:19] {2219} INFO - iteration 275, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:14:21] {2392} INFO -  at 175.8s,\testimator catboost's best error=0.1263,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:14:21] {2219} INFO - iteration 276, current learner catboost\n",
      "[flaml.automl.logger: 07-22 14:14:23] {2392} INFO -  at 178.1s,\testimator catboost's best error=0.1263,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:14:23] {2219} INFO - iteration 277, current learner rf\n",
      "[flaml.automl.logger: 07-22 14:14:24] {2392} INFO -  at 179.2s,\testimator rf's best error=0.1303,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:14:24] {2219} INFO - iteration 278, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:14:24] {2392} INFO -  at 179.5s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:14:24] {2219} INFO - iteration 279, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-22 14:14:25] {2392} INFO -  at 179.7s,\testimator xgb_limitdepth's best error=0.1324,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:14:25] {2219} INFO - iteration 280, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:14:25] {2392} INFO -  at 179.8s,\testimator lgbm's best error=0.1335,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:14:25] {2219} INFO - iteration 281, current learner lgbm\n",
      "[flaml.automl.logger: 07-22 14:14:25] {2392} INFO -  at 180.0s,\testimator lgbm's best error=0.1335,\tbest estimator catboost's best error=0.1263\n",
      "[flaml.automl.logger: 07-22 14:14:25] {2628} INFO - retrain catboost for 0.2s\n",
      "[flaml.automl.logger: 07-22 14:14:25] {2631} INFO - retrained model: <catboost.core.CatBoostClassifier object at 0x000001F5B1E45250>\n",
      "[flaml.automl.logger: 07-22 14:14:25] {1931} INFO - fit succeeded\n",
      "[flaml.automl.logger: 07-22 14:14:25] {1932} INFO - Time taken to find the best model: 75.78905940055847\n"
     ]
    }
   ],
   "source": [
    "automl = AutoML()\n",
    "automl.fit(X_train, y_train, task=\"classification\", time_budget=180, seed=42)\n",
    "results_df = pd.concat(\n",
    "    [results_df,\n",
    "    auto_ml_get_results(name=\"Auto ML - Training for 3 minutes\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy (training)</th>\n",
       "      <th>Accuracy (validation)</th>\n",
       "      <th>Precision (validation)</th>\n",
       "      <th>Recall (validation)</th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Auto ML - Default Parameters - Scoring on ROC AUC</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.801</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scoring on f1</th>\n",
       "      <td>0.851</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.795</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training for 3 minutes</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.801</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Accuracy (training)  \\\n",
       "Auto ML - Default Parameters - Scoring on ROC AUC                0.863   \n",
       "Scoring on f1                                                    0.851   \n",
       "Training for 3 minutes                                           0.863   \n",
       "\n",
       "                                                   Accuracy (validation)  \\\n",
       "Auto ML - Default Parameters - Scoring on ROC AUC                  0.811   \n",
       "Scoring on f1                                                      0.804   \n",
       "Training for 3 minutes                                             0.811   \n",
       "\n",
       "                                                   Precision (validation)  \\\n",
       "Auto ML - Default Parameters - Scoring on ROC AUC                   0.802   \n",
       "Scoring on f1                                                       0.795   \n",
       "Training for 3 minutes                                              0.802   \n",
       "\n",
       "                                                   Recall (validation)    AUC  \\\n",
       "Auto ML - Default Parameters - Scoring on ROC AUC                0.800  0.800   \n",
       "Scoring on f1                                                    0.795  0.795   \n",
       "Training for 3 minutes                                           0.800  0.800   \n",
       "\n",
       "                                                      f1  FP  FN  \n",
       "Auto ML - Default Parameters - Scoring on ROC AUC  0.801  13  14  \n",
       "Scoring on f1                                      0.795  14  14  \n",
       "Training for 3 minutes                             0.801  13  14  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare this with some other ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_train(name=\"XGBoost\", X_train=X_train, X_validate=X_validate,\n",
    "              y_train=y_train, y_validate=y_validate,\n",
    "              model=XGBClassifier(random_state=42)\n",
    "              ):\n",
    "\n",
    "     model.fit(X_train, y_train)\n",
    "\n",
    "     y_pred_train = model.predict(X_train)\n",
    "     y_pred_val = model.predict(X_validate)\n",
    "\n",
    "     tn, fp, fn, tp = confusion_matrix(y_validate, y_pred_val, labels=[0, 1]).ravel()\n",
    "\n",
    "     return pd.DataFrame({\n",
    "            'Accuracy (training)': np.mean(y_pred_train == y_train),\n",
    "            'Accuracy (validation)': np.mean(y_pred_val == y_validate),\n",
    "            'Precision (validation)': precision_score(y_validate, y_pred_val, average='macro'),\n",
    "            'Recall (validation)': recall_score(y_validate, y_pred_val, average='macro'),\n",
    "            \"AUC\": roc_auc_score(y_validate, y_pred_val),\n",
    "            \"f1\": f1_score(y_validate, y_pred_val, average='macro'),\n",
    "            \"FP\": fp,\n",
    "            \"FN\": fn\n",
    "          }, index=[name]\n",
    ").round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 212, number of negative: 357\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000839 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 230\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.372583 -> initscore=-0.521150\n",
      "[LightGBM] [Info] Start training from score -0.521150\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy (training)</th>\n",
       "      <th>Accuracy (validation)</th>\n",
       "      <th>Precision (validation)</th>\n",
       "      <th>Recall (validation)</th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Auto ML - Default Parameters - Scoring on ROC AUC</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.801</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scoring on f1</th>\n",
       "      <td>0.851</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.795</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training for 3 minutes</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.801</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.979</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.787</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree (Defaults)</th>\n",
       "      <td>0.988</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.767</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest (Defaults)</th>\n",
       "      <td>0.988</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.753</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM (Defaults)</th>\n",
       "      <td>0.961</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.808</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Catboost (Defaults)</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.808</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Accuracy (training)  \\\n",
       "Auto ML - Default Parameters - Scoring on ROC AUC                0.863   \n",
       "Scoring on f1                                                    0.851   \n",
       "Training for 3 minutes                                           0.863   \n",
       "XGBoost                                                          0.979   \n",
       "Decision Tree (Defaults)                                         0.988   \n",
       "Random Forest (Defaults)                                         0.988   \n",
       "LightGBM (Defaults)                                              0.961   \n",
       "Catboost (Defaults)                                              0.923   \n",
       "\n",
       "                                                   Accuracy (validation)  \\\n",
       "Auto ML - Default Parameters - Scoring on ROC AUC                  0.811   \n",
       "Scoring on f1                                                      0.804   \n",
       "Training for 3 minutes                                             0.811   \n",
       "XGBoost                                                            0.797   \n",
       "Decision Tree (Defaults)                                           0.776   \n",
       "Random Forest (Defaults)                                           0.762   \n",
       "LightGBM (Defaults)                                                0.818   \n",
       "Catboost (Defaults)                                                0.818   \n",
       "\n",
       "                                                   Precision (validation)  \\\n",
       "Auto ML - Default Parameters - Scoring on ROC AUC                   0.802   \n",
       "Scoring on f1                                                       0.795   \n",
       "Training for 3 minutes                                              0.802   \n",
       "XGBoost                                                             0.788   \n",
       "Decision Tree (Defaults)                                            0.765   \n",
       "Random Forest (Defaults)                                            0.751   \n",
       "LightGBM (Defaults)                                                 0.810   \n",
       "Catboost (Defaults)                                                 0.810   \n",
       "\n",
       "                                                   Recall (validation)    AUC  \\\n",
       "Auto ML - Default Parameters - Scoring on ROC AUC                0.800  0.800   \n",
       "Scoring on f1                                                    0.795  0.795   \n",
       "Training for 3 minutes                                           0.800  0.800   \n",
       "XGBoost                                                          0.786  0.786   \n",
       "Decision Tree (Defaults)                                         0.768  0.768   \n",
       "Random Forest (Defaults)                                         0.757  0.757   \n",
       "LightGBM (Defaults)                                              0.806  0.806   \n",
       "Catboost (Defaults)                                              0.806  0.806   \n",
       "\n",
       "                                                      f1  FP  FN  \n",
       "Auto ML - Default Parameters - Scoring on ROC AUC  0.801  13  14  \n",
       "Scoring on f1                                      0.795  14  14  \n",
       "Training for 3 minutes                             0.801  13  14  \n",
       "XGBoost                                            0.787  14  15  \n",
       "Decision Tree (Defaults)                           0.767  17  15  \n",
       "Random Forest (Defaults)                           0.753  19  15  \n",
       "LightGBM (Defaults)                                0.808  12  14  \n",
       "Catboost (Defaults)                                0.808  12  14  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.concat(\n",
    "    [results_df,\n",
    "     fit_train(),\n",
    "     fit_train(name=\"Decision Tree (Defaults)\", model=DecisionTreeClassifier()),\n",
    "     fit_train(name=\"Random Forest (Defaults)\", model=RandomForestClassifier(random_state=42)),\n",
    "     fit_train(name=\"LightGBM (Defaults)\", model=LGBMClassifier(random_state=42)),\n",
    "     fit_train(name=\"Catboost (Defaults)\", model=CatBoostClassifier(random_state=42, verbose=False)),\n",
    "\n",
    "     ]\n",
    ")\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy (training)</th>\n",
       "      <th>Accuracy (validation)</th>\n",
       "      <th>Precision (validation)</th>\n",
       "      <th>Recall (validation)</th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LightGBM (Defaults)</th>\n",
       "      <td>0.961</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.808</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Catboost (Defaults)</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.808</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Auto ML - Default Parameters - Scoring on ROC AUC</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.801</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training for 3 minutes</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.801</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scoring on f1</th>\n",
       "      <td>0.851</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.795</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.979</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.787</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree (Defaults)</th>\n",
       "      <td>0.988</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.767</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest (Defaults)</th>\n",
       "      <td>0.988</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.753</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Accuracy (training)  \\\n",
       "LightGBM (Defaults)                                              0.961   \n",
       "Catboost (Defaults)                                              0.923   \n",
       "Auto ML - Default Parameters - Scoring on ROC AUC                0.863   \n",
       "Training for 3 minutes                                           0.863   \n",
       "Scoring on f1                                                    0.851   \n",
       "XGBoost                                                          0.979   \n",
       "Decision Tree (Defaults)                                         0.988   \n",
       "Random Forest (Defaults)                                         0.988   \n",
       "\n",
       "                                                   Accuracy (validation)  \\\n",
       "LightGBM (Defaults)                                                0.818   \n",
       "Catboost (Defaults)                                                0.818   \n",
       "Auto ML - Default Parameters - Scoring on ROC AUC                  0.811   \n",
       "Training for 3 minutes                                             0.811   \n",
       "Scoring on f1                                                      0.804   \n",
       "XGBoost                                                            0.797   \n",
       "Decision Tree (Defaults)                                           0.776   \n",
       "Random Forest (Defaults)                                           0.762   \n",
       "\n",
       "                                                   Precision (validation)  \\\n",
       "LightGBM (Defaults)                                                 0.810   \n",
       "Catboost (Defaults)                                                 0.810   \n",
       "Auto ML - Default Parameters - Scoring on ROC AUC                   0.802   \n",
       "Training for 3 minutes                                              0.802   \n",
       "Scoring on f1                                                       0.795   \n",
       "XGBoost                                                             0.788   \n",
       "Decision Tree (Defaults)                                            0.765   \n",
       "Random Forest (Defaults)                                            0.751   \n",
       "\n",
       "                                                   Recall (validation)    AUC  \\\n",
       "LightGBM (Defaults)                                              0.806  0.806   \n",
       "Catboost (Defaults)                                              0.806  0.806   \n",
       "Auto ML - Default Parameters - Scoring on ROC AUC                0.800  0.800   \n",
       "Training for 3 minutes                                           0.800  0.800   \n",
       "Scoring on f1                                                    0.795  0.795   \n",
       "XGBoost                                                          0.786  0.786   \n",
       "Decision Tree (Defaults)                                         0.768  0.768   \n",
       "Random Forest (Defaults)                                         0.757  0.757   \n",
       "\n",
       "                                                      f1  FP  FN  \n",
       "LightGBM (Defaults)                                0.808  12  14  \n",
       "Catboost (Defaults)                                0.808  12  14  \n",
       "Auto ML - Default Parameters - Scoring on ROC AUC  0.801  13  14  \n",
       "Training for 3 minutes                             0.801  13  14  \n",
       "Scoring on f1                                      0.795  14  14  \n",
       "XGBoost                                            0.787  14  15  \n",
       "Decision Tree (Defaults)                           0.767  17  15  \n",
       "Random Forest (Defaults)                           0.753  19  15  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values(\"Accuracy (validation)\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at another way to quickly compare the performance of the different models.\n",
    "\n",
    "We will rank each model by its performance against the other models, with a lower number indicating better performance relative to the other models (e.g. the model with the highest precision will be ranked 1; the model with the lowest number of false negatives will be ranked 1).\n",
    "\n",
    "We will omit training accuracy from our calculations as we are more interested in its likely 'real-world' performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy (validation)</th>\n",
       "      <th>Precision (validation)</th>\n",
       "      <th>Recall (validation)</th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>Rank Sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LightGBM (Defaults)</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Catboost (Defaults)</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Auto ML - Default Parameters - Scoring on ROC AUC</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training for 3 minutes</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scoring on f1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree (Defaults)</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest (Defaults)</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Accuracy (validation)  \\\n",
       "LightGBM (Defaults)                                                    1   \n",
       "Catboost (Defaults)                                                    1   \n",
       "Auto ML - Default Parameters - Scoring on ROC AUC                      2   \n",
       "Training for 3 minutes                                                 2   \n",
       "Scoring on f1                                                          3   \n",
       "XGBoost                                                                4   \n",
       "Decision Tree (Defaults)                                               5   \n",
       "Random Forest (Defaults)                                               6   \n",
       "\n",
       "                                                   Precision (validation)  \\\n",
       "LightGBM (Defaults)                                                     1   \n",
       "Catboost (Defaults)                                                     1   \n",
       "Auto ML - Default Parameters - Scoring on ROC AUC                       2   \n",
       "Training for 3 minutes                                                  2   \n",
       "Scoring on f1                                                           3   \n",
       "XGBoost                                                                 4   \n",
       "Decision Tree (Defaults)                                                5   \n",
       "Random Forest (Defaults)                                                6   \n",
       "\n",
       "                                                   Recall (validation)  AUC  \\\n",
       "LightGBM (Defaults)                                                  1    1   \n",
       "Catboost (Defaults)                                                  1    1   \n",
       "Auto ML - Default Parameters - Scoring on ROC AUC                    2    2   \n",
       "Training for 3 minutes                                               2    2   \n",
       "Scoring on f1                                                        3    3   \n",
       "XGBoost                                                              4    4   \n",
       "Decision Tree (Defaults)                                             5    5   \n",
       "Random Forest (Defaults)                                             6    6   \n",
       "\n",
       "                                                   f1  FP  FN  Rank Sum  \n",
       "LightGBM (Defaults)                                 1   1   1         7  \n",
       "Catboost (Defaults)                                 1   1   1         7  \n",
       "Auto ML - Default Parameters - Scoring on ROC AUC   2   2   1        13  \n",
       "Training for 3 minutes                              2   2   1        13  \n",
       "Scoring on f1                                       3   3   1        19  \n",
       "XGBoost                                             4   3   2        25  \n",
       "Decision Tree (Defaults)                            5   4   2        31  \n",
       "Random Forest (Defaults)                            6   5   2        37  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranking_df_high_good = results_df[['Accuracy (validation)', 'Precision (validation)', 'Recall (validation)', 'AUC', 'f1']].rank(method='dense', ascending=False).convert_dtypes()\n",
    "ranking_df_low_good = results_df[['FP', 'FN']].rank(method='dense', ascending=True).convert_dtypes()\n",
    "\n",
    "ranking_df = ranking_df_high_good.merge(ranking_df_low_good, left_index=True, right_index=True)\n",
    "\n",
    "ranking_df['Rank Sum'] = ranking_df.sum(axis=1)\n",
    "ranking_df = ranking_df.sort_values('Rank Sum', ascending=True).convert_dtypes()\n",
    "ranking_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could plot this output as well as everything is on the same scale (though we will omit the rank sum) as that's much larger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Performance Ranking (Higher Rank Value = Worse)'}, xlabel='Rank of Performance'>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ranking_df.drop(columns=\"Rank Sum\").plot(\n",
    "    kind=\"barh\",\n",
    "    title=\"Performance Ranking (Higher Rank Value = Worse)\",\n",
    "    xlabel=\"Rank of Performance\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
